{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f298d294",
   "metadata": {},
   "source": [
    "Python Jupyter Notebook that combines two previously separated algorithm for:\n",
    "1. Taking imported raw polls and converting to vote shares for every candidate in every constituency\n",
    "2. Analysing election results for a range of specified dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8acf157f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Algorithm details\n",
    "AlgorithmName = \"CoreComboPollElectionAlogrithm\"\n",
    "AlgorithmVersion = \"1_0\"\n",
    "AlgorithmDate = \"20240703\"\n",
    "\n",
    "# Version 0_1 New combined 'core' and 'MRP' algorithms taking out the MRPs to be used in a different analysis\n",
    "# Version 1_0 Fully tested version of the core and MRP combined algorithm\n",
    "\n",
    "# Construct PollAnalysisAlogrithm string\n",
    "ElectionAnalysisAlgorithm = AlgorithmName + \"_\" + AlgorithmVersion + \"_\" + AlgorithmDate\n",
    "PollAnalysisAlgorithm = AlgorithmName + \"_\" + AlgorithmVersion + \"_\" + AlgorithmDate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76f9782b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required modules\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from datetime import timedelta\n",
    "import numpy as np\n",
    "import pyodbc\n",
    "import sqlalchemy\n",
    "from sqlalchemy import create_engine\n",
    "import urllib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d84e1879",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set core variables for the rest of the algorithm\n",
    "ElectionDate = datetime.date(2024, 7, 4) # Set the date of the election\n",
    "\n",
    "AutoStartDateFlag = True # if true, use the next date after the last date analysed in the database\n",
    "# OR the date of the earliest poll to added, whichever is sooner\n",
    "AutoEndDateFlag = True # if true, use the date of the last poll\n",
    "\n",
    "ManualStartDate = datetime.date(2024, 1, 1) # start date of election analyses if auto is not used\n",
    "ManualEndDate = datetime.date(2024, 1, 15) # end date of election analyses if auto is not used\n",
    "EarliestStartDate = datetime.date(2024, 1, 1) # the earliest possible start date that the election analysis will use\n",
    "\n",
    "DeleteAnalysesFlag = True # if true, already existing analyses will be delete\n",
    "\n",
    "DetailedRankThreshold = 5 # Variable for identifying from a poll's rank, whether it is a 'national' or 'detailed' poll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a19306b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connect to database 'UK_General_Election' using SQlAlchemy\n",
    "connection_str = \"DRIVER={SQL SERVER};SERVER=DANZPOOTA;DATABASE=UK_General_Election;TRUSTED_CONNECTION=YES\"\n",
    "params = urllib.parse.quote_plus(connection_str)\n",
    "engine = create_engine('mssql+pyodbc:///?odbc_connect=%s' % params)\n",
    "conn = engine.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "270dcee8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-03\n",
      "2024-07-03\n"
     ]
    }
   ],
   "source": [
    "# Determine the start and end date for the election analysis loop\n",
    "if AutoStartDateFlag == False:\n",
    "    StartDate = ManualStartDate\n",
    "else:\n",
    "    LastAnalysisDateQuery = \"SELECT TOP(1) ElectionPredictionDate FROM ElectionPredictionMeta ORDER BY ElectionPredictionDate DESC\"\n",
    "    LastAnalysisDateList = [i[0] for i in engine.execute(LastAnalysisDateQuery)]\n",
    "    \n",
    "    try:\n",
    "        LastAnalysisDate = LastAnalysisDateList[0]\n",
    "    except:\n",
    "        LastAnalysisDate = \"\"\n",
    "    \n",
    "    EarliestNewPollQuery = \"SELECT TOP(1) pm.PollDate from PollMeta AS pm LEFT JOIN PollAnalysisMeta AS pam ON pm.PollID = pam.PollID WHERE pam.PollID IS NULL ORDER BY pm.PollDate ASC\"\n",
    "    EarliestNewPollList = [i[0] for i in engine.execute(EarliestNewPollQuery)]\n",
    "    try:\n",
    "        EarliestNewPollDate = EarliestNewPollList[0]\n",
    "    except:\n",
    "        EarliestNewPollDate = \"\"\n",
    "    \n",
    "    if LastAnalysisDate == \"\":\n",
    "        StartDate = pd.to_datetime(EarliestStartDate).date()\n",
    "    elif LastAnalysisDate < EarliestNewPollDate or EarliestNewPollDate == \"\":\n",
    "        StartDate = pd.to_datetime(LastAnalysisDate).date() + timedelta(days=1)\n",
    "    elif pd.to_datetime(EarliestNewPollDate).date() > EarliestStartDate:    \n",
    "        StartDate = pd.to_datetime(EarliestNewPollDate).date()\n",
    "    else:\n",
    "        StartDate = pd.to_datetime(EarliestStartDate).date()\n",
    "    \n",
    "if AutoEndDateFlag == False:\n",
    "    EndDate = ManualEndDate\n",
    "else:\n",
    "    LastPollDateQuery = \"\"\"SELECT TOP(1) PollDate from PollMeta Order by PollDate DESC\"\"\"\n",
    "    LastPollDateList = [i[0] for i in engine.execute(LastPollDateQuery)]\n",
    "    LastPollDate = LastPollDateList[0]\n",
    "    EndDate = pd.to_datetime(LastPollDate).date()\n",
    "    \n",
    "print(StartDate)\n",
    "print(EndDate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "33186d3e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['20240703JL PartnersITL1Region-NINAAll']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get list of unanalysed polls to the loop around\n",
    "PollsListQuery = \"SELECT A.PollID from PollMeta A LEFT JOIN PollAnalysisMeta B ON A.PollID = B.PollID WHERE B.PollID IS NULL\"\n",
    "PollsList = [i[0] for i in engine.execute(PollsListQuery)]\n",
    "PollsList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4204e71",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 46.9 ms\n",
      "Wall time: 1.45 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Main algorithm loop to convert poll vote shres into candidate vote shares\n",
    "for PollID in PollsList:\n",
    "    \n",
    "    # Get the Poll Meta data from the database    \n",
    "    PollMetaQuery = \"SELECT * From PollMeta WHERE PollID = '<PollID>'\"\n",
    "    PollMetaQuery = PollMetaQuery.replace(\"<PollID>\",PollID)\n",
    "    PollMeta_df = pd.read_sql(PollMetaQuery,conn)\n",
    "    \n",
    "    # Get key variables for polls\n",
    "    PollType = PollMeta_df.at[0,'PollType']\n",
    "    PollScope = PollMeta_df.at[0,'PollScope']    \n",
    "    \n",
    "    #Query for generating list of applicable poll regions\n",
    "    AllRegionsQuery = \"SELECT RegionName FROM RegionRegionTypes WHERE RegionType = '<PollType>'\"\n",
    "    \n",
    "    # Get from database all of the region vote shares relating to the PollID\n",
    "    PollSharesQuery = \"SELECT PollDetailsID, RegionName, Constituency, Party, VoteShare AS PollShare FROM PollDetails WHERE PollID = '<PollID>' ORDER BY RegionName, Party\"\n",
    "    PollSharesQuery = PollSharesQuery.replace(\"<PollID>\",PollID)\n",
    "    PollShares_df = pd.read_sql(PollSharesQuery,conn)\n",
    "    \n",
    "    # Check to see if it is a constituency only poll as this needs to be handled very differently\n",
    "    # The alogrithm cannot be allowed to look for region shares as it will not find any for a constituency poll\n",
    "    if PollType == \"Constituency\":\n",
    "        ConstituencyPollFlag = True\n",
    "        MRPPollFlag = False\n",
    "\n",
    "        PreviousRegionSharesQuery = \"SELECT CandidateID, Constituency, Party, PreviousShare FROM Candidates WHERE Constituency = '<Constituency>'\"\n",
    "        PreviousRegionSharesQuery = PreviousRegionSharesQuery.replace(\"<Constituency>\",PollScope)\n",
    "        PreviousRegionShares_df = pd.read_sql(PreviousRegionSharesQuery,conn)\n",
    "        \n",
    "        ConstituencyPollRegion = PollShares_df.at[0,'RegionName']      \n",
    "        \n",
    "        # Join the dataframes on 'Party'\n",
    "        PreviousRegionShares_df = PreviousRegionShares_df.merge(PollShares_df[['Party','PollDetailsID','PollShare']], how='left', on='Party')\n",
    "\n",
    "        # Determine swing\n",
    "        PreviousRegionShares_df['Swing'] = PreviousRegionShares_df['PollShare'] - PreviousRegionShares_df['PreviousShare']\n",
    "        \n",
    "        ConstituencyShares_df = PreviousRegionShares_df.copy()\n",
    "        ConstituencyShares_df['RegionName'] = ConstituencyShares_df['Constituency']\n",
    "        \n",
    "    elif PollType == \"MRP632\" or PollType == \"MRP631\":\n",
    "        MRPPollFlag = True\n",
    "        ConstituencyPollFlag = False\n",
    "        \n",
    "        PreviousRegionSharesQuery = \"\"\"SELECT can.CandidateID, can.Constituency, can.Party, can.PreviousShare FROM Candidates AS can\n",
    "        INNER JOIN Constituencies AS con ON con.ConstituencyName = can.Constituency\n",
    "        INNER JOIN RegionConstituencies AS rc ON rc.ConstituencyName = con.ConstituencyName\n",
    "        WHERE rc.RegionName = '<PollType>'\"\"\"\n",
    "        PreviousRegionSharesQuery = PreviousRegionSharesQuery.replace(\"<PollType>\",PollType)\n",
    "        PreviousRegionShares_df = pd.read_sql(PreviousRegionSharesQuery,conn)\n",
    "        \n",
    "        PollShares_df['CandidateID'] = PollShares_df['Constituency'] + PollShares_df['Party']\n",
    "        \n",
    "        PreviousRegionShares_df = PreviousRegionShares_df.merge(PollShares_df[['CandidateID','PollDetailsID','PollShare']], how='left', on='CandidateID')\n",
    "        \n",
    "        PreviousRegionShares_df['Swing'] = PreviousRegionShares_df['PollShare'] - PreviousRegionShares_df['PreviousShare']\n",
    "        \n",
    "        ConstituencyShares_df = PreviousRegionShares_df.copy()\n",
    "        ConstituencyShares_df['RegionName'] = ConstituencyShares_df['Constituency']\n",
    "        \n",
    "    else:\n",
    "        ConstituencyPollFlag = False\n",
    "        MRPPollFlag = False\n",
    "        \n",
    "        # Generate a list of all of the regions applicable to a poll when it is not a constituency one\n",
    "        if PollScope == \"All\":\n",
    "            AllRegionsQuery = AllRegionsQuery.replace(\"<PollType>\",PollType)\n",
    "            RegionsList = [i[0] for i in engine.execute(AllRegionsQuery)]\n",
    "        else:\n",
    "            RegionsList = [PollScope]     \n",
    "\n",
    "        # Query for the region vote shares from the previous election\n",
    "        PreviousRegionSharesQuery = \"\"\"SELECT r.RegionName, can.Party, SUM(can.PreviousVotes) AS 'TotalVotes',\n",
    "        CAST(SUM(can.PreviousVotes) AS FLOAT) / SUM(SUM(can.PreviousVotes)) OVER() AS 'RawPreviousShare',\n",
    "        SUM(can.PreviousStanding) AS 'PreviousCandidates',\n",
    "        SUM(can.CurrentStanding) AS 'CurrentCandidates'\n",
    "        FROM Candidates AS can\n",
    "        INNER JOIN Constituencies as con ON con.ConstituencyName = can.Constituency\n",
    "        INNER JOIN RegionConstituencies AS rc ON  rc.ConstituencyName = con.ConstituencyName\n",
    "        INNER JOIN Regions AS r ON r.RegionName = rc.RegionName\n",
    "        INNER JOIN RegionRegionTypes AS rrt ON rrt.RegionName = r.RegionName\n",
    "        WHERE r.RegionName = '<RegionName>' AND rrt.RegionType = '<RegionType>'\n",
    "        GROUP BY r.RegionName, can.Party\n",
    "        ORDER BY r.RegionName, can.Party\"\"\"\n",
    "\n",
    "        PreviousRegionSharesQuery = PreviousRegionSharesQuery.replace(\"<RegionType>\",PollType)\n",
    "\n",
    "        # Get from database all of the vote shares for the poll regions from the previous election\n",
    "        PreviousRegionShares_df = pd.DataFrame(columns=[\"RegionName\",\"Party\",\"TotalVotes\",\"RawPreviousShare\",\"PreviousCandidates\",\"CurrentCandidates\"])\n",
    "\n",
    "        # Loop through all regions applicable to this particular poll\n",
    "        for Region in RegionsList:\n",
    "            # Run query for the raw previous region shares\n",
    "            ModRegionSharesQuery = PreviousRegionSharesQuery.replace(\"<RegionName>\",Region)\n",
    "            IndRegionShares_df = pd.read_sql(ModRegionSharesQuery,conn)  \n",
    "\n",
    "            # Join this particular region's numbers to the overall dataframe for this poll\n",
    "            PreviousRegionShares_df = pd.concat([PreviousRegionShares_df,IndRegionShares_df],axis=0)\n",
    "\n",
    "        # Reset the index column\n",
    "        PreviousRegionShares_df.reset_index(drop=True,inplace=True)\n",
    "\n",
    "        # Replace all 0 values with 1000 to ensure the new vote share can be calculated without dividing by zero\n",
    "        PreviousRegionShares_df['PreviousCandidates'].replace(0,1000,inplace=True)\n",
    "\n",
    "        #Calculated the adjusted previous share based on the number of candidates actually standing\n",
    "        PreviousRegionShares_df['PreviousShare'] = PreviousRegionShares_df['RawPreviousShare'] * PreviousRegionShares_df['CurrentCandidates']/PreviousRegionShares_df['PreviousCandidates']\n",
    "\n",
    "        # Revert previous candidates back to zero\n",
    "        PreviousRegionShares_df['PreviousCandidates'].replace(1000,0,inplace=True)    \n",
    "    \n",
    "        # Create a column to join the two dataframes\n",
    "        PollShares_df['RegionParty'] = PollShares_df['RegionName'] + PollShares_df['Party']\n",
    "        PreviousRegionShares_df['RegionParty'] = PreviousRegionShares_df['RegionName'] + PreviousRegionShares_df['Party']\n",
    "        \n",
    "        # Join the dataframes on 'RegionParty'\n",
    "        PreviousRegionShares_df = PreviousRegionShares_df.merge(PollShares_df[['PollDetailsID','RegionParty','PollShare']], how='left', on='RegionParty')\n",
    "\n",
    "        # Determine swing\n",
    "        PreviousRegionShares_df['Swing'] = PreviousRegionShares_df['PollShare'] - PreviousRegionShares_df['PreviousShare']  \n",
    "\n",
    "        # Query for pulling out previous election shares for applicable constituencies\n",
    "        CandidatesQuery = \"\"\"SELECT can.CandidateID, r.RegionName, can.Constituency, can.Party, can.PreviousShare\n",
    "        FROM Candidates AS can\n",
    "        INNER JOIN Constituencies as con ON con.ConstituencyName = can.Constituency\n",
    "        INNER JOIN RegionConstituencies AS rc ON  rc.ConstituencyName = con.ConstituencyName\n",
    "        INNER JOIN Regions AS r ON r.RegionName = rc.RegionName\n",
    "        INNER JOIN RegionRegionTypes AS rrt ON rrt.RegionName = r.RegionName\n",
    "        WHERE r.RegionName = '<RegionName>' AND rrt.RegionType = '<RegionType>'\n",
    "        AND can.CurrentStanding = 1\n",
    "        ORDER BY can.Constituency, can.Party\"\"\"\n",
    "\n",
    "        CandidatesQuery = CandidatesQuery.replace(\"<RegionType>\",PollType)\n",
    "\n",
    "        # Calculate the swings for every candidate in every constituency\n",
    "        ConstituencyShares_df = pd.DataFrame(columns=[\"CandidateID\",\"RegionName\",\"Constituency\",\"Party\",\"PreviousShare\",\"NewShareRaw\",\"VoteShare\"])\n",
    "        IndConstituencyShares_df = pd.DataFrame(columns=[\"CandidateID\",\"RegionName\",\"Constituency\",\"Party\",\"PreviousShare\",\"NewShareRaw\",\"VoteShare\"])\n",
    "\n",
    "        # Need to cycle through every region to pull out the candidates for each in turn, then get the swing for each\n",
    "        for Region in RegionsList:\n",
    "\n",
    "            ModCandidatesQuery = CandidatesQuery.replace(\"<RegionName>\",Region)\n",
    "            IndConstituencyShares_df = pd.read_sql(ModCandidatesQuery,conn)   \n",
    "\n",
    "            ConstituencyShares_df = pd.concat([ConstituencyShares_df,IndConstituencyShares_df],axis=0)\n",
    "\n",
    "        ConstituencyShares_df.reset_index(drop=True,inplace=True)\n",
    "    \n",
    "        # Create 'RegionParty' to allow merging with the previous region shares dataframe\n",
    "        ConstituencyShares_df['RegionParty'] = ConstituencyShares_df['RegionName'] + ConstituencyShares_df['Party']\n",
    "        \n",
    "        # Join the dataframes on 'RegionParty'\n",
    "        ConstituencyShares_df = ConstituencyShares_df.merge(PreviousRegionShares_df[['PollDetailsID','RegionParty','Swing']], how='left', on='RegionParty')\n",
    "                \n",
    "    # Exit of Constituency poll IF statement    \n",
    "    # Ensure the datatypes are numeric of the columns to be used in the calculation\n",
    "    ConstituencyShares_df[\"PreviousShare\"] = pd.to_numeric(ConstituencyShares_df[\"PreviousShare\"])\n",
    "    ConstituencyShares_df[\"Swing\"] = pd.to_numeric(ConstituencyShares_df[\"Swing\"])\n",
    "\n",
    "    ConstituencyShares_df[\"NewShareRaw\"] = ConstituencyShares_df[\"PreviousShare\"] + ConstituencyShares_df[\"Swing\"] \n",
    "    ConstituencyShares_df[\"NewShareRaw\"] = np.where(ConstituencyShares_df[\"NewShareRaw\"] < 0, 0,ConstituencyShares_df[\"NewShareRaw\"])\n",
    "\n",
    "    # Determine the factor needed to ensure vote shares for each constituency sum to 1\n",
    "    ConstituencyShares_df['ConstRawShareTotals'] = ConstituencyShares_df['NewShareRaw'].groupby(ConstituencyShares_df['Constituency']).transform('sum')\n",
    "\n",
    "    # Modify the raw vote shares to ensure they sum to 1\n",
    "    ConstituencyShares_df['VoteShare'] = ConstituencyShares_df['NewShareRaw']/ConstituencyShares_df['ConstRawShareTotals']\n",
    "\n",
    "    ConstituencyShares_df['VoteShareCheck'] = ConstituencyShares_df['VoteShare'].groupby(ConstituencyShares_df['Constituency']).transform('sum')\n",
    "\n",
    "    # Create PollAnalysisMeta details for inserting into database\n",
    "    PollAnalysisMeta_df = pd.DataFrame(columns=[\"PollID\",\"PollAnalysisDate\",\"PollAnalysisAlgorithm\"])\n",
    "\n",
    "    PollAnalysisMeta_df.at[0,\"PollID\"] = PollID\n",
    "    PollAnalysisMeta_df.at[0,\"PollAnalysisAlgorithm\"] = PollAnalysisAlgorithm\n",
    "\n",
    "    # The date of the analysis is always today's date\n",
    "    PollAnalysisMeta_df.at[0,\"PollAnalysisDate\"] = datetime.date.today()\n",
    "\n",
    "    PollAnalysisMeta_df.to_sql('PollAnalysisMeta', conn, if_exists='append', index=False)\n",
    "\n",
    "    # Initial poll analysis values are now inserted into the database to allow these to be queried for the constituency shares\n",
    "    PollAnalysisRegions_df = PreviousRegionShares_df[['PollDetailsID','Swing']].copy()\n",
    "\n",
    "    # Get the recently inserted PollAnalysis ID from the database\n",
    "    PollAnalysisIDQuery = \"SELECT PollAnalysisID FROM PollAnalysisMeta WHERE PollID = '<PollID>'\"\n",
    "    PollAnalysisIDQuery = PollAnalysisIDQuery.replace(\"<PollID>\",PollID)\n",
    "\n",
    "    PollAnalysisID = [i[0] for i in engine.execute(PollAnalysisIDQuery)][0]\n",
    "    PollAnalysisRegions_df['PollAnalysisID'] = PollAnalysisID\n",
    "\n",
    "    PollAnalysisRegions_df.to_sql('PollAnalysisRegions', conn, if_exists='append', index=False)\n",
    "    \n",
    "    # Create the dataframe for insertion into the database and insert\n",
    "    ConstituencyShares_df['PollAnalysisRegionID'] = ConstituencyShares_df['PollDetailsID'] + PollAnalysisID\n",
    "    PollAnalysisConstituencies_df = ConstituencyShares_df[['PollAnalysisRegionID','CandidateID','VoteShare']]\n",
    "    PollAnalysisConstituencies_df.to_sql('PollAnalysisConstituencies', conn, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "327b57a1",
   "metadata": {},
   "source": [
    "Separation between the previoulsy segragated poll analysis and election analysis algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "657e6f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "DeleteAnalysisQueryRaw = \"\"\"DELETE eppu FROM ElectionPredictionPollsUsed AS eppu\n",
    "INNER JOIN ElectionPredictionMeta AS epm ON epm.ElectionPredictionID = eppu.ElectionPredictionID\n",
    "WHERE epm.ElectionPredictionDate = '<ElectionPredictionDate>' AND epm.ElectionPredictionID LIKE '%<Type>%'\n",
    "\n",
    "DELETE epc FROM ElectionPredictionCandidates AS epc\n",
    "INNER JOIN ElectionPredictionMeta AS epm ON epm.ElectionPredictionID = epc.ElectionPredictionID\n",
    "WHERE epm.ElectionPredictionDate = '<ElectionPredictionDate>' AND epm.ElectionPredictionID LIKE '%<Type>%'\n",
    "\n",
    "DELETE epcon FROM ElectionPredictionConstituencies AS epcon\n",
    "INNER JOIN ElectionPredictionMeta AS epm ON epm.ElectionPredictionID = epcon.ElectionPredictionID\n",
    "WHERE epm.ElectionPredictionDate = '<ElectionPredictionDate>' AND epm.ElectionPredictionID LIKE '%<Type>%'\n",
    "\n",
    "DELETE epo FROM ElectionPredictionOverall AS epo\n",
    "INNER JOIN ElectionPredictionMeta AS epm ON epm.ElectionPredictionID = epo.ElectionPredictionID\n",
    "WHERE epm.ElectionPredictionDate = '<ElectionPredictionDate>' AND epm.ElectionPredictionID LIKE '%<Type>%'\n",
    "\n",
    "DELETE FROM ElectionPredictionMeta WHERE ElectionPredictionDate = '<ElectionPredictionDate>' AND ElectionPredictionID LIKE '%<Type>%'\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aecfba44",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End: 2024-07-03\n",
      "CPU times: total: 266 ms\n",
      "Wall time: 14.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Combined Election Analysis\n",
    "\n",
    "# Setup variables for the loop\n",
    "ElectionPredictionDate = StartDate\n",
    "Delta = timedelta(days=1)\n",
    "\n",
    "# Loop around all of the analysis dates\n",
    "while ElectionPredictionDate <= EndDate:    \n",
    "    #print(\"Start:\",ElectionPredictionDate)\n",
    "\n",
    "    DaysToElection = ElectionDate - ElectionPredictionDate\n",
    "    if DaysToElection.days <= 35:\n",
    "        NationalValidPeriod = 7\n",
    "        DetailedValidPeriod = 35\n",
    "    else:\n",
    "        NationalValidPeriod = 30\n",
    "        DetailedValidPeriod = 100\n",
    "\n",
    "    #print(\"Prediction Date:\",ElectionPredictionDate,\"Days To Election:\",DaysToElection.days,\"NationalValidPeriod:\",NationalValidPeriod)\n",
    "\n",
    "    #Check if there is already an analysis for this analysis date\n",
    "    ElectionPredictionDateStr = datetime.datetime.strftime(ElectionPredictionDate, '%Y%m%d')\n",
    "    AnalysisExistsQuery = \"SELECT Count(ElectionPredictionID) FROM ElectionPredictionMeta WHERE ElectionPredictionDate = '<ElectionPredictionDate>' AND ElectionPredictionID LIKE '%Core%'\"\n",
    "    AnalysisExistsQuery = AnalysisExistsQuery.replace('<ElectionPredictionDate>',ElectionPredictionDateStr)\n",
    "    AnalysisExistsList = [i[0] for i in engine.execute(AnalysisExistsQuery)]\n",
    "    AnalysisExistsInt = AnalysisExistsList[0]\n",
    "    #print(AnalysisExistsInt)\n",
    "\n",
    "    if AnalysisExistsInt < 1 or DeleteAnalysesFlag == True:\n",
    "\n",
    "        if AnalysisExistsInt >=1:\n",
    "            # Delete the analysis\n",
    "            DeleteAnalysisQueryType = DeleteAnalysisQueryRaw.replace('<Type>','Core')\n",
    "            DeleteAnalysisQuery = DeleteAnalysisQueryType.replace('<ElectionPredictionDate>',ElectionPredictionDateStr)\n",
    "            engine.execute(DeleteAnalysisQuery)\n",
    "\n",
    "        # Get the list of polls that have actually been analysed and incorporated into the database\n",
    "        AnalysedPollsQuery = \"\"\"SELECT pam.PollID, pm.Pollster, pm.PollType, pm.PollScope, pm.PollDate, rt.RegionTypeRank  FROM PollAnalysisMeta AS pam\n",
    "        INNER JOIN PollMeta AS pm ON pm.PollID = pam.PollID\n",
    "        INNER JOIN RegionTypes AS rt ON rt.RegionType = pm.PollType\n",
    "        WHERE pm.PollType NOT LIKE '%MRP%'\"\"\"\n",
    "\n",
    "        AnalysedPolls_df = pd.read_sql(AnalysedPollsQuery,conn)\n",
    "\n",
    "        # Add prediction date and convert to datetime date so that it can be used in a calcualtion\n",
    "        AnalysedPolls_df['PredictionDate'] = ElectionPredictionDate\n",
    "        AnalysedPolls_df['PredictionDate'] = pd.to_datetime(AnalysedPolls_df['PredictionDate'])\n",
    "\n",
    "        # Convert the date column to datetime type\n",
    "        AnalysedPolls_df['PollDate'] = pd.to_datetime(AnalysedPolls_df['PollDate'])\n",
    "\n",
    "        # Determine how many days from the prediction date a poll was taken\n",
    "        AnalysedPolls_df['DateDelta'] = AnalysedPolls_df['PredictionDate'] - AnalysedPolls_df['PollDate']\n",
    "\n",
    "        # Assign a rank to each poll\n",
    "        AnalysedPolls_df['PollRank'] = np.where(AnalysedPolls_df['PollScope']=='All',AnalysedPolls_df['RegionTypeRank'],AnalysedPolls_df['RegionTypeRank']-1)\n",
    "\n",
    "        # Determine the applicability of each poll based on the day delta\n",
    "        AnalysedPolls_df['PollApplicability'] = np.where((AnalysedPolls_df['DateDelta'] <= pd.Timedelta(DetailedValidPeriod, unit=\"d\")) \\\n",
    "                                                         & (AnalysedPolls_df['DateDelta'] >= pd.Timedelta(0, unit=\"d\")) \\\n",
    "                                                         & (AnalysedPolls_df['PollRank'] <= DetailedRankThreshold),1, \\\n",
    "                                                         np.where((AnalysedPolls_df['DateDelta'] <= pd.Timedelta(NationalValidPeriod, unit=\"d\")) \\\n",
    "                                                         & (AnalysedPolls_df['DateDelta'] >= pd.Timedelta(0, unit=\"d\")) \\\n",
    "                                                         & (AnalysedPolls_df['PollRank'] > DetailedRankThreshold),1,0))\n",
    "\n",
    "        # Copy the polls that fall within the date delta to a new data frame\n",
    "        ApplicablePolls_df = AnalysedPolls_df[AnalysedPolls_df['PollApplicability'] == 1].copy()\n",
    "        ApplicablePolls_df.reset_index(drop=True,inplace=True)\n",
    "\n",
    "        # Check for duplicate polls of the same type\n",
    "        # Create column that would contain the info to check for duplicates\n",
    "        ApplicablePolls_df['DuplicateCheck'] = ApplicablePolls_df['Pollster'] + ApplicablePolls_df['PollType'] + ApplicablePolls_df['PollScope'] \n",
    "\n",
    "        # The dataframe needs to be sorted to ensure the latest poll is kept and older duplicates are removed\n",
    "        ApplicablePolls_df.sort_values(by='DateDelta',inplace=True)\n",
    "\n",
    "        # Drop duplicates\n",
    "        ApplicablePolls_df.drop_duplicates(subset=['DuplicateCheck'],inplace=True)\n",
    "\n",
    "        # Reset the dataframe index after being sorted and duplicates removed\n",
    "        ApplicablePolls_df.reset_index(drop=True,inplace=True)\n",
    "\n",
    "        # Main algorithm to create resultant candidate shares\n",
    "        # Create dataframe with every candidate as rows\n",
    "        SelectCandidatesQuery = \"SELECT can.CandidateID, can.Constituency, can.Party, can.PreviousShare FROM Candidates AS can WHERE can.CurrentStanding = 1\"\n",
    "        Candidates_df = pd.read_sql(SelectCandidatesQuery,conn)\n",
    "\n",
    "        # Descending Loop around every rank\n",
    "        # start point = max rank from applicable polls df\n",
    "        MaxRank = ApplicablePolls_df['PollRank'].max()\n",
    "        MinRank = ApplicablePolls_df['PollRank'].min()\n",
    "\n",
    "        # Boolean to record if this is the first run through for the running total\n",
    "        FirstRun = True\n",
    "\n",
    "        for Rank in range(MaxRank,MinRank-1,-1):\n",
    "\n",
    "            # Create df from all polls relating to the current rank\n",
    "            # First create list of applicable polls\n",
    "            RankApplicablePolls_df = ApplicablePolls_df[ApplicablePolls_df['PollRank'] == Rank].copy()\n",
    "            RankApplicablePolls = RankApplicablePolls_df['PollID'].tolist()\n",
    "\n",
    "            for PollID in RankApplicablePolls:\n",
    "                # print(Rank,\":\",PollID)        \n",
    "\n",
    "                # Query for getting the poll analysis details\n",
    "                SelectPollDetailsQuery = \"\"\"SELECT pac.CandidateID, pac.VoteShare AS '<PollID>' FROM PollAnalysisConstituencies AS pac\n",
    "                INNER JOIN PollAnalysisRegions AS par on par.PollAnalysisRegionID = pac.PollAnalysisRegionID\n",
    "                INNER JOIN PollAnalysisMeta AS pam ON pam.PollAnalysisID = par.PollAnalysisID\n",
    "                WHERE pam.PollID = '<PollID>'\n",
    "                ORDER BY pac.CandidateID\"\"\"\n",
    "\n",
    "                # Insert the PollID into the query\n",
    "                SelectPollDetailsQuery = SelectPollDetailsQuery.replace(\"<PollID>\",PollID)\n",
    "\n",
    "                # Pull query into a data frame for the results\n",
    "                PollAnalysis_df = pd.read_sql(SelectPollDetailsQuery,conn)\n",
    "\n",
    "                # Merge with Candidates_df\n",
    "                # PreviousRegionShares_df = PreviousRegionShares_df.merge(PollRegionShares_df[['PollDetailsID','RegionParty','PollShare']], how='left', on='RegionParty')\n",
    "                Candidates_df = Candidates_df.merge(PollAnalysis_df, how='left', on='CandidateID')\n",
    "\n",
    "            # Average the columns for each row (candidate) for this rank\n",
    "            if RankApplicablePolls != []:\n",
    "                if FirstRun == True:\n",
    "                    Candidates_df[Rank] = Candidates_df[RankApplicablePolls].mean(axis=1)\n",
    "                    # Set the first run to false now that the loop has been gone though\n",
    "                    FirstRun = False\n",
    "                else:\n",
    "                    RankApplicablePolls.append(PreviousRank)\n",
    "                    Candidates_df[Rank] = Candidates_df[RankApplicablePolls].mean(axis=1)\n",
    "\n",
    "                # Record the last rank to be evaluated        \n",
    "                PreviousRank = Rank\n",
    "\n",
    "        Candidates_df['VoteShareRaw'] = Candidates_df[Rank].copy()\n",
    "\n",
    "        # Determine the factor needed to ensure vote shares for each constituency sum to 1\n",
    "        Candidates_df['ConstRawShareTotals'] = Candidates_df['VoteShareRaw'].groupby(Candidates_df['Constituency']).transform('sum')\n",
    "\n",
    "        # Modify the raw vote shares to ensure they sum to 1\n",
    "        Candidates_df['VoteShare'] = Candidates_df['VoteShareRaw']/Candidates_df['ConstRawShareTotals']\n",
    "\n",
    "        Candidates_df['VoteShareCheck'] = Candidates_df['VoteShare'].groupby(Candidates_df['Constituency']).transform('sum')\n",
    "\n",
    "        Candidates_df['VoteShareChange'] = Candidates_df['VoteShare'] - Candidates_df['PreviousShare']\n",
    "\n",
    "        # Determine the constituency winners\n",
    "        # https://stackoverflow.com/questions/15705630/get-the-rows-which-have-the-max-value-in-groups-using-groupby\n",
    "        #df.sort_values('count').drop_duplicates(['Sp', 'Mt'], keep='last')\n",
    "        ConstWinners_df = Candidates_df[['Constituency','Party','VoteShare','VoteShareChange']].copy()\n",
    "        ConstWinners_df = ConstWinners_df.sort_values(['Constituency','VoteShare'],ascending = [True, False])\n",
    "        ConstWinners_df['Majority'] = ConstWinners_df['VoteShare'] - ConstWinners_df['VoteShare'].shift(-1)\n",
    "        ConstWinners_df['SecondParty'] = ConstWinners_df['Party'].shift(-1)\n",
    "\n",
    "        # Calculate the swing for each winner\n",
    "        ConstWinners_df['Swing'] = (ConstWinners_df['VoteShareChange'] - ConstWinners_df['VoteShareChange'].shift(-1))/2\n",
    "\n",
    "        # Keep only the winners of each constituency\n",
    "        ConstWinners_df = ConstWinners_df.sort_values('VoteShare').drop_duplicates(['Constituency'], keep='last')\n",
    "        ConstWinners_df = ConstWinners_df.sort_values('Constituency')\n",
    "\n",
    "        ConstWinners_df.reset_index(drop=True,inplace=True)\n",
    "\n",
    "        # Determine how many constituencies each party has won\n",
    "        OverallResults_df = ConstWinners_df[['Party','Constituency']].groupby('Party').count()\n",
    "        OverallResults_df.reset_index(drop=False,inplace=True)\n",
    "\n",
    "        # Determine total vote shares for each party\n",
    "        OverallVoteShare_df = Candidates_df[['Party','VoteShare']].copy()\n",
    "        OverallVoteShare_df['PartyShare'] = OverallVoteShare_df['VoteShare'].groupby(OverallVoteShare_df['Party']).transform('sum')\n",
    "        OverallVoteShare_df = OverallVoteShare_df.drop_duplicates(['Party'], keep='last')\n",
    "        OverallVoteShare_df.drop(['VoteShare'], axis=1, inplace=True)\n",
    "        OverallVoteShare_df.sort_values(by='PartyShare', ascending=False, inplace=True)\n",
    "        OverallVoteShare_df['PartyShare'] = OverallVoteShare_df['PartyShare']/OverallVoteShare_df['PartyShare'].sum()\n",
    "        OverallVoteShare_df.reset_index(drop=True,inplace=True)\n",
    "\n",
    "        # Combine the overall vote shares and constituency numbers into one dataframe\n",
    "        Overall_df = OverallVoteShare_df.merge(OverallResults_df, how='left', on='Party')\n",
    "        Overall_df = Overall_df.fillna(0)\n",
    "        Overall_df.sort_values(by='Constituency', ascending=False, inplace=True)\n",
    "        Overall_df.reset_index(drop=True,inplace=True)\n",
    "\n",
    "        # Election prediction analysis date is today\n",
    "        ElectionAnalysisDate = datetime.date.today()\n",
    "\n",
    "        # Create the election prediction ID for the database\n",
    "        ElectionPredictionID = datetime.datetime.strftime(ElectionAnalysisDate, '%Y%m%d') + datetime.datetime.strftime(ElectionPredictionDate, '%Y%m%d') + ElectionAnalysisAlgorithm\n",
    "\n",
    "        # Create the ElectionPredictionMeta table content for this analysis\n",
    "        ElectionPredictionMeta_df = pd.DataFrame(columns=[\"ElectionAnalysisDate\",\"ElectionPredictionDate\",\"ElectionAnalysisAlgorithm\"])\n",
    "        ElectionPredictionMeta_df.at[0,\"ElectionAnalysisDate\"] = ElectionAnalysisDate\n",
    "        ElectionPredictionMeta_df.at[0,\"ElectionPredictionDate\"] = ElectionPredictionDate\n",
    "        ElectionPredictionMeta_df.at[0,\"ElectionAnalysisAlgorithm\"] = ElectionAnalysisAlgorithm\n",
    "\n",
    "        # Create the ElectionPredictionPolls used content\n",
    "        ElectionPredictionPollsUsed_df = pd.DataFrame(columns=['ElectionPredictionID','PollID'])\n",
    "        ElectionPredictionPollsUsed_df['PollID'] = ApplicablePolls_df['PollID'].copy()\n",
    "        ElectionPredictionPollsUsed_df['ElectionPredictionID'] = ElectionPredictionID\n",
    "\n",
    "        # Create ElectionPredictionCandidates data\n",
    "        ElectionPredictionCandidates_df = pd.DataFrame(columns=['ElectionPredictionID','CandidateID','VoteShare'])\n",
    "        ElectionPredictionCandidates_df[['CandidateID','VoteShare']] = Candidates_df[['CandidateID','VoteShare']].copy()\n",
    "        ElectionPredictionCandidates_df['ElectionPredictionID'] = ElectionPredictionID\n",
    "\n",
    "        # Create ElectionPredictionConstituencies data\n",
    "        ElectionPredictionConstituencies_df = pd.DataFrame(columns=['ElectionPredictionID','Constituency','WinningParty','SecondParty','VoteShare','Majority','GAIN','LOSS','Swing'])\n",
    "        ElectionPredictionConstituencies_df[['Constituency','WinningParty','SecondParty','VoteShare','Majority','Swing']] = ConstWinners_df[['Constituency','Party','SecondParty','VoteShare','Majority','Swing']].copy()\n",
    "\n",
    "        PreviousWinnersQuery = \"SELECT ConstituencyName AS 'Constituency', FirstParty AS 'PreviousWinner' FROM Constituencies\"\n",
    "        PreviousWinners_df = pd.read_sql(PreviousWinnersQuery,conn)\n",
    "        ElectionPredictionConstituencies_df = ElectionPredictionConstituencies_df.merge(PreviousWinners_df, how='left', on='Constituency')\n",
    "        ElectionPredictionConstituencies_df['GAIN'] = np.where(ElectionPredictionConstituencies_df['WinningParty'] == ElectionPredictionConstituencies_df['PreviousWinner'],ElectionPredictionConstituencies_df['WinningParty']+\" HOLD\",ElectionPredictionConstituencies_df['WinningParty']+\" GAIN\")\n",
    "        ElectionPredictionConstituencies_df['LOSS'] = np.where(ElectionPredictionConstituencies_df['WinningParty'] == ElectionPredictionConstituencies_df['PreviousWinner'],ElectionPredictionConstituencies_df['PreviousWinner']+\" HOLD\",ElectionPredictionConstituencies_df['PreviousWinner']+\" LOSS\")\n",
    "        ElectionPredictionConstituencies_df['ElectionPredictionID'] = ElectionPredictionID\n",
    "\n",
    "        # Create ElectionPredictionOverall data\n",
    "        ElectionPredictionOverall_df = pd.DataFrame(columns=['ElectionPredictionID','Party','VoteShare','Constituencies'])\n",
    "        ElectionPredictionOverall_df[['Party','VoteShare','Constituencies']] = Overall_df[['Party','PartyShare','Constituency']].copy()\n",
    "        ElectionPredictionOverall_df['Constituencies'] = ElectionPredictionOverall_df['Constituencies'].astype('int')\n",
    "        ElectionPredictionOverall_df['ElectionPredictionID'] = ElectionPredictionID\n",
    "\n",
    "        # Insert data into the database\n",
    "        ElectionPredictionMeta_df.to_sql('ElectionPredictionMeta', conn, if_exists='append', index=False)\n",
    "        ElectionPredictionPollsUsed_df.to_sql('ElectionPredictionPollsUsed', conn, if_exists='append', index=False)\n",
    "        ElectionPredictionCandidates_df.to_sql('ElectionPredictionCandidates', conn, if_exists='append', index=False)\n",
    "        ElectionPredictionConstituencies_df.to_sql('ElectionPredictionConstituencies', conn, if_exists='append', index=False)\n",
    "        ElectionPredictionOverall_df.to_sql('ElectionPredictionOverall', conn, if_exists='append', index=False)\n",
    "\n",
    "    print(\"End:\",ElectionPredictionDate)\n",
    "    ElectionPredictionDate += Delta # Increment ElectionPredictionDate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ca5e63ae",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Party  PartyShare  Constituency\n",
      "0      Lab    0.396562         411.0\n",
      "1      Con    0.215925         142.0\n",
      "2       LD    0.106831          53.0\n",
      "3      SNP    0.029277          18.0\n",
      "4       SF    0.006485           7.0\n",
      "5      DUP    0.006294           6.0\n",
      "6    Other    0.019951           3.0\n",
      "7       PC    0.006076           3.0\n",
      "8     APNI    0.005289           2.0\n",
      "9     SDLP    0.003572           2.0\n",
      "10  Reform    0.139072           1.0\n",
      "11   Green    0.060132           1.0\n",
      "12     UUP    0.003699           1.0\n",
      "13     TUV    0.000835           0.0\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    print(Overall_df)\n",
    "except:\n",
    "    print('No Overall_df to show')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "149a023a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the candidates dataframe to a csv for testing\n",
    "try:\n",
    "    Candidates_df.to_csv('C:/Users/danmu/Documents/Elections/2024_Python/candidates.csv',encoding='utf-8')\n",
    "except:\n",
    "    print('No Candidates_df to show')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7b721593",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change algorithm details for the MRP algorithm\n",
    "AlgorithmName = \"MRPComboPollElectionAlogrithm\"\n",
    "AlgorithmVersion = \"1_0\"\n",
    "AlgorithmDate = \"20240703\"\n",
    "\n",
    "# Version 0_1 New combine 'core' and 'MRP' algorithms taking out the MRPs to be used in a different analysis\n",
    "# Version 1_0 of the combined core and MRP model\n",
    "\n",
    "# Construct PollAnalysisAlogrithm string\n",
    "ElectionAnalysisAlgorithm = AlgorithmName + \"_\" + AlgorithmVersion + \"_\" + AlgorithmDate\n",
    "PollAnalysisAlgorithm = AlgorithmName + \"_\" + AlgorithmVersion + \"_\" + AlgorithmDate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c9b548d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End: 2024-07-03\n",
      "CPU times: total: 328 ms\n",
      "Wall time: 15.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Combined Election Analysis\n",
    "\n",
    "# Setup variables for the loop\n",
    "ElectionPredictionDate = StartDate\n",
    "Delta = timedelta(days=1)\n",
    "\n",
    "# Loop around all of the analysis dates\n",
    "while ElectionPredictionDate <= EndDate:    \n",
    "    #print(\"Start:\",ElectionPredictionDate)\n",
    "\n",
    "    DaysToElection = ElectionDate - ElectionPredictionDate\n",
    "    if DaysToElection.days <= 35:\n",
    "        NationalValidPeriod = 7\n",
    "        DetailedValidPeriod = 35\n",
    "    else:\n",
    "        NationalValidPeriod = 30\n",
    "        DetailedValidPeriod = 100\n",
    "\n",
    "    #print(\"Prediction Date:\",ElectionPredictionDate,\"Days To Election:\",DaysToElection.days,\"NationalValidPeriod:\",NationalValidPeriod)\n",
    "\n",
    "    #Check if there is already an analysis for this analysis date\n",
    "    ElectionPredictionDateStr = datetime.datetime.strftime(ElectionPredictionDate, '%Y%m%d')\n",
    "    AnalysisExistsQuery = \"SELECT Count(ElectionPredictionID) FROM ElectionPredictionMeta WHERE ElectionPredictionDate = '<ElectionPredictionDate>' AND ElectionPredictionID LIKE '%MRP%'\"\n",
    "    AnalysisExistsQuery = AnalysisExistsQuery.replace('<ElectionPredictionDate>',ElectionPredictionDateStr)\n",
    "    AnalysisExistsList = [i[0] for i in engine.execute(AnalysisExistsQuery)]\n",
    "    AnalysisExistsInt = AnalysisExistsList[0]\n",
    "    #print(AnalysisExistsInt)\n",
    "\n",
    "    if AnalysisExistsInt < 1 or DeleteAnalysesFlag == True:\n",
    "\n",
    "        if AnalysisExistsInt >=1:\n",
    "            # Delete the analysis\n",
    "            DeleteAnalysisQueryType = DeleteAnalysisQueryRaw.replace('<Type>','MRP')\n",
    "            DeleteAnalysisQuery = DeleteAnalysisQueryType.replace('<ElectionPredictionDate>',ElectionPredictionDateStr)\n",
    "            engine.execute(DeleteAnalysisQuery)\n",
    "\n",
    "        # Get the list of polls that have actually been analysed and incorporated into the database\n",
    "        AnalysedPollsQuery = \"\"\"SELECT pam.PollID, pm.Pollster, pm.PollType, pm.PollScope, pm.PollDate, rt.RegionTypeRank  FROM PollAnalysisMeta AS pam\n",
    "        INNER JOIN PollMeta AS pm ON pm.PollID = pam.PollID\n",
    "        INNER JOIN RegionTypes AS rt ON rt.RegionType = pm.PollType\"\"\"\n",
    "\n",
    "        AnalysedPolls_df = pd.read_sql(AnalysedPollsQuery,conn)\n",
    "\n",
    "        # Add prediction date and convert to datetime date so that it can be used in a calcualtion\n",
    "        AnalysedPolls_df['PredictionDate'] = ElectionPredictionDate\n",
    "        AnalysedPolls_df['PredictionDate'] = pd.to_datetime(AnalysedPolls_df['PredictionDate'])\n",
    "\n",
    "        # Convert the date column to datetime type\n",
    "        AnalysedPolls_df['PollDate'] = pd.to_datetime(AnalysedPolls_df['PollDate'])\n",
    "\n",
    "        # Determine how many days from the prediction date a poll was taken\n",
    "        AnalysedPolls_df['DateDelta'] = AnalysedPolls_df['PredictionDate'] - AnalysedPolls_df['PollDate']\n",
    "\n",
    "        # Assign a rank to each poll\n",
    "        AnalysedPolls_df['PollRank'] = np.where(AnalysedPolls_df['PollScope']=='All',AnalysedPolls_df['RegionTypeRank'],AnalysedPolls_df['RegionTypeRank']-1)\n",
    "\n",
    "        # Determine the applicability of each poll based on the day delta\n",
    "        AnalysedPolls_df['PollApplicability'] = np.where((AnalysedPolls_df['DateDelta'] <= pd.Timedelta(DetailedValidPeriod, unit=\"d\")) \\\n",
    "                                                         & (AnalysedPolls_df['DateDelta'] >= pd.Timedelta(0, unit=\"d\")) \\\n",
    "                                                         & (AnalysedPolls_df['PollRank'] <= DetailedRankThreshold),1, \\\n",
    "                                                         np.where((AnalysedPolls_df['DateDelta'] <= pd.Timedelta(NationalValidPeriod, unit=\"d\")) \\\n",
    "                                                         & (AnalysedPolls_df['DateDelta'] >= pd.Timedelta(0, unit=\"d\")) \\\n",
    "                                                         & (AnalysedPolls_df['PollRank'] > DetailedRankThreshold),1,0))\n",
    "\n",
    "        # Copy the polls that fall within the date delta to a new data frame\n",
    "        ApplicablePolls_df = AnalysedPolls_df[AnalysedPolls_df['PollApplicability'] == 1].copy()\n",
    "        ApplicablePolls_df.reset_index(drop=True,inplace=True)\n",
    "\n",
    "        # Check for duplicate polls of the same type\n",
    "        # Create column that would contain the info to check for duplicates\n",
    "        ApplicablePolls_df['DuplicateCheck'] = ApplicablePolls_df['Pollster'] + ApplicablePolls_df['PollType'] + ApplicablePolls_df['PollScope'] \n",
    "\n",
    "        # The dataframe needs to be sorted to ensure the latest poll is kept and older duplicates are removed\n",
    "        ApplicablePolls_df.sort_values(by='DateDelta',inplace=True)\n",
    "\n",
    "        # Drop duplicates\n",
    "        ApplicablePolls_df.drop_duplicates(subset=['DuplicateCheck'],inplace=True)\n",
    "\n",
    "        # Reset the dataframe index after being sorted and duplicates removed\n",
    "        ApplicablePolls_df.reset_index(drop=True,inplace=True)\n",
    "\n",
    "        # Main algorithm to create resultant candidate shares\n",
    "        # Create dataframe with every candidate as rows\n",
    "        SelectCandidatesQuery = \"SELECT can.CandidateID, can.Constituency, can.Party, can.PreviousShare FROM Candidates AS can WHERE can.CurrentStanding = 1\"\n",
    "        Candidates_df = pd.read_sql(SelectCandidatesQuery,conn)\n",
    "\n",
    "        # Descending Loop around every rank\n",
    "        # start point = max rank from applicable polls df\n",
    "        MaxRank = ApplicablePolls_df['PollRank'].max()\n",
    "        MinRank = ApplicablePolls_df['PollRank'].min()\n",
    "\n",
    "        # Boolean to record if this is the first run through for the running total\n",
    "        FirstRun = True\n",
    "\n",
    "        for Rank in range(MaxRank,MinRank-1,-1):\n",
    "\n",
    "            # Create df from all polls relating to the current rank\n",
    "            # First create list of applicable polls\n",
    "            RankApplicablePolls_df = ApplicablePolls_df[ApplicablePolls_df['PollRank'] == Rank].copy()\n",
    "            RankApplicablePolls = RankApplicablePolls_df['PollID'].tolist()\n",
    "\n",
    "            for PollID in RankApplicablePolls:\n",
    "                # print(Rank,\":\",PollID)        \n",
    "\n",
    "                # Query for getting the poll analysis details\n",
    "                SelectPollDetailsQuery = \"\"\"SELECT pac.CandidateID, pac.VoteShare AS '<PollID>' FROM PollAnalysisConstituencies AS pac\n",
    "                INNER JOIN PollAnalysisRegions AS par on par.PollAnalysisRegionID = pac.PollAnalysisRegionID\n",
    "                INNER JOIN PollAnalysisMeta AS pam ON pam.PollAnalysisID = par.PollAnalysisID\n",
    "                WHERE pam.PollID = '<PollID>'\n",
    "                ORDER BY pac.CandidateID\"\"\"\n",
    "\n",
    "                # Insert the PollID into the query\n",
    "                SelectPollDetailsQuery = SelectPollDetailsQuery.replace(\"<PollID>\",PollID)\n",
    "\n",
    "                # Pull query into a data frame for the results\n",
    "                PollAnalysis_df = pd.read_sql(SelectPollDetailsQuery,conn)\n",
    "\n",
    "                # Merge with Candidates_df\n",
    "                # PreviousRegionShares_df = PreviousRegionShares_df.merge(PollRegionShares_df[['PollDetailsID','RegionParty','PollShare']], how='left', on='RegionParty')\n",
    "                Candidates_df = Candidates_df.merge(PollAnalysis_df, how='left', on='CandidateID')\n",
    "\n",
    "            # Average the columns for each row (candidate) for this rank\n",
    "            if RankApplicablePolls != []:\n",
    "                if FirstRun == True:\n",
    "                    Candidates_df[Rank] = Candidates_df[RankApplicablePolls].mean(axis=1)\n",
    "                    # Set the first run to false now that the loop has been gone though\n",
    "                    FirstRun = False\n",
    "                else:\n",
    "                    RankApplicablePolls.append(PreviousRank)\n",
    "                    Candidates_df[Rank] = Candidates_df[RankApplicablePolls].mean(axis=1)\n",
    "\n",
    "                # Record the last rank to be evaluated        \n",
    "                PreviousRank = Rank\n",
    "\n",
    "        Candidates_df['VoteShareRaw'] = Candidates_df[Rank].copy()\n",
    "\n",
    "        # Determine the factor needed to ensure vote shares for each constituency sum to 1\n",
    "        Candidates_df['ConstRawShareTotals'] = Candidates_df['VoteShareRaw'].groupby(Candidates_df['Constituency']).transform('sum')\n",
    "\n",
    "        # Modify the raw vote shares to ensure they sum to 1\n",
    "        Candidates_df['VoteShare'] = Candidates_df['VoteShareRaw']/Candidates_df['ConstRawShareTotals']\n",
    "\n",
    "        Candidates_df['VoteShareCheck'] = Candidates_df['VoteShare'].groupby(Candidates_df['Constituency']).transform('sum')\n",
    "\n",
    "        Candidates_df['VoteShareChange'] = Candidates_df['VoteShare'] - Candidates_df['PreviousShare']\n",
    "\n",
    "        # Determine the constituency winners\n",
    "        # https://stackoverflow.com/questions/15705630/get-the-rows-which-have-the-max-value-in-groups-using-groupby\n",
    "        #df.sort_values('count').drop_duplicates(['Sp', 'Mt'], keep='last')\n",
    "        ConstWinners_df = Candidates_df[['Constituency','Party','VoteShare','VoteShareChange']].copy()\n",
    "        ConstWinners_df = ConstWinners_df.sort_values(['Constituency','VoteShare'],ascending = [True, False])\n",
    "        ConstWinners_df['Majority'] = ConstWinners_df['VoteShare'] - ConstWinners_df['VoteShare'].shift(-1)\n",
    "        ConstWinners_df['SecondParty'] = ConstWinners_df['Party'].shift(-1)\n",
    "\n",
    "        # Calculate the swing for each winner\n",
    "        ConstWinners_df['Swing'] = (ConstWinners_df['VoteShareChange'] - ConstWinners_df['VoteShareChange'].shift(-1))/2\n",
    "\n",
    "        # Keep only the winners of each constituency\n",
    "        ConstWinners_df = ConstWinners_df.sort_values('VoteShare').drop_duplicates(['Constituency'], keep='last')\n",
    "        ConstWinners_df = ConstWinners_df.sort_values('Constituency')\n",
    "\n",
    "        ConstWinners_df.reset_index(drop=True,inplace=True)\n",
    "\n",
    "        # Determine how many constituencies each party has won\n",
    "        OverallResults_df = ConstWinners_df[['Party','Constituency']].groupby('Party').count()\n",
    "        OverallResults_df.reset_index(drop=False,inplace=True)\n",
    "\n",
    "        # Determine total vote shares for each party\n",
    "        OverallVoteShare_df = Candidates_df[['Party','VoteShare']].copy()\n",
    "        OverallVoteShare_df['PartyShare'] = OverallVoteShare_df['VoteShare'].groupby(OverallVoteShare_df['Party']).transform('sum')\n",
    "        OverallVoteShare_df = OverallVoteShare_df.drop_duplicates(['Party'], keep='last')\n",
    "        OverallVoteShare_df.drop(['VoteShare'], axis=1, inplace=True)\n",
    "        OverallVoteShare_df.sort_values(by='PartyShare', ascending=False, inplace=True)\n",
    "        OverallVoteShare_df['PartyShare'] = OverallVoteShare_df['PartyShare']/OverallVoteShare_df['PartyShare'].sum()\n",
    "        OverallVoteShare_df.reset_index(drop=True,inplace=True)\n",
    "\n",
    "        # Combine the overall vote shares and constituency numbers into one dataframe\n",
    "        Overall_df = OverallVoteShare_df.merge(OverallResults_df, how='left', on='Party')\n",
    "        Overall_df = Overall_df.fillna(0)\n",
    "        Overall_df.sort_values(by='Constituency', ascending=False, inplace=True)\n",
    "        Overall_df.reset_index(drop=True,inplace=True)\n",
    "\n",
    "        # Election prediction analysis date is today\n",
    "        ElectionAnalysisDate = datetime.date.today()\n",
    "\n",
    "        # Create the election prediction ID for the database\n",
    "        ElectionPredictionID = datetime.datetime.strftime(ElectionAnalysisDate, '%Y%m%d') + datetime.datetime.strftime(ElectionPredictionDate, '%Y%m%d') + ElectionAnalysisAlgorithm\n",
    "\n",
    "        # Create the ElectionPredictionMeta table content for this analysis\n",
    "        ElectionPredictionMeta_df = pd.DataFrame(columns=[\"ElectionAnalysisDate\",\"ElectionPredictionDate\",\"ElectionAnalysisAlgorithm\"])\n",
    "        ElectionPredictionMeta_df.at[0,\"ElectionAnalysisDate\"] = ElectionAnalysisDate\n",
    "        ElectionPredictionMeta_df.at[0,\"ElectionPredictionDate\"] = ElectionPredictionDate\n",
    "        ElectionPredictionMeta_df.at[0,\"ElectionAnalysisAlgorithm\"] = ElectionAnalysisAlgorithm\n",
    "\n",
    "        # Create the ElectionPredictionPolls used content\n",
    "        ElectionPredictionPollsUsed_df = pd.DataFrame(columns=['ElectionPredictionID','PollID'])\n",
    "        ElectionPredictionPollsUsed_df['PollID'] = ApplicablePolls_df['PollID'].copy()\n",
    "        ElectionPredictionPollsUsed_df['ElectionPredictionID'] = ElectionPredictionID\n",
    "\n",
    "        # Create ElectionPredictionCandidates data\n",
    "        ElectionPredictionCandidates_df = pd.DataFrame(columns=['ElectionPredictionID','CandidateID','VoteShare'])\n",
    "        ElectionPredictionCandidates_df[['CandidateID','VoteShare']] = Candidates_df[['CandidateID','VoteShare']].copy()\n",
    "        ElectionPredictionCandidates_df['ElectionPredictionID'] = ElectionPredictionID\n",
    "\n",
    "        # Create ElectionPredictionConstituencies data\n",
    "        ElectionPredictionConstituencies_df = pd.DataFrame(columns=['ElectionPredictionID','Constituency','WinningParty','SecondParty','VoteShare','Majority','GAIN','LOSS','Swing'])\n",
    "        ElectionPredictionConstituencies_df[['Constituency','WinningParty','SecondParty','VoteShare','Majority','Swing']] = ConstWinners_df[['Constituency','Party','SecondParty','VoteShare','Majority','Swing']].copy()\n",
    "\n",
    "        PreviousWinnersQuery = \"SELECT ConstituencyName AS 'Constituency', FirstParty AS 'PreviousWinner' FROM Constituencies\"\n",
    "        PreviousWinners_df = pd.read_sql(PreviousWinnersQuery,conn)\n",
    "        ElectionPredictionConstituencies_df = ElectionPredictionConstituencies_df.merge(PreviousWinners_df, how='left', on='Constituency')\n",
    "        ElectionPredictionConstituencies_df['GAIN'] = np.where(ElectionPredictionConstituencies_df['WinningParty'] == ElectionPredictionConstituencies_df['PreviousWinner'],ElectionPredictionConstituencies_df['WinningParty']+\" HOLD\",ElectionPredictionConstituencies_df['WinningParty']+\" GAIN\")\n",
    "        ElectionPredictionConstituencies_df['LOSS'] = np.where(ElectionPredictionConstituencies_df['WinningParty'] == ElectionPredictionConstituencies_df['PreviousWinner'],ElectionPredictionConstituencies_df['PreviousWinner']+\" HOLD\",ElectionPredictionConstituencies_df['PreviousWinner']+\" LOSS\")\n",
    "        ElectionPredictionConstituencies_df['ElectionPredictionID'] = ElectionPredictionID\n",
    "\n",
    "        # Create ElectionPredictionOverall data\n",
    "        ElectionPredictionOverall_df = pd.DataFrame(columns=['ElectionPredictionID','Party','VoteShare','Constituencies'])\n",
    "        ElectionPredictionOverall_df[['Party','VoteShare','Constituencies']] = Overall_df[['Party','PartyShare','Constituency']].copy()\n",
    "        ElectionPredictionOverall_df['Constituencies'] = ElectionPredictionOverall_df['Constituencies'].astype('int')\n",
    "        ElectionPredictionOverall_df['ElectionPredictionID'] = ElectionPredictionID\n",
    "\n",
    "        # Insert data into the database\n",
    "        ElectionPredictionMeta_df.to_sql('ElectionPredictionMeta', conn, if_exists='append', index=False)\n",
    "        ElectionPredictionPollsUsed_df.to_sql('ElectionPredictionPollsUsed', conn, if_exists='append', index=False)\n",
    "        ElectionPredictionCandidates_df.to_sql('ElectionPredictionCandidates', conn, if_exists='append', index=False)\n",
    "        ElectionPredictionConstituencies_df.to_sql('ElectionPredictionConstituencies', conn, if_exists='append', index=False)\n",
    "        ElectionPredictionOverall_df.to_sql('ElectionPredictionOverall', conn, if_exists='append', index=False)\n",
    "\n",
    "    print(\"End:\",ElectionPredictionDate)\n",
    "    ElectionPredictionDate += Delta # Increment ElectionPredictionDate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b86b09c6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Party  PartyShare  Constituency\n",
      "0      Lab    0.398644         453.0\n",
      "1      Con    0.218897          91.0\n",
      "2       LD    0.107911          63.0\n",
      "3      SNP    0.027633          16.0\n",
      "4       SF    0.006485           7.0\n",
      "5      DUP    0.006294           6.0\n",
      "6    Green    0.056056           3.0\n",
      "7       PC    0.006177           3.0\n",
      "8   Reform    0.142163           2.0\n",
      "9     APNI    0.005289           2.0\n",
      "10    SDLP    0.003572           2.0\n",
      "11   Other    0.016346           1.0\n",
      "12     UUP    0.003699           1.0\n",
      "13     TUV    0.000835           0.0\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    print(Overall_df)\n",
    "except:\n",
    "    print('No Overall_df to show')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c2add402",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Close the connection with the database\n",
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
