{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f298d294",
   "metadata": {},
   "source": [
    "Python Jupyter Notebook that combines two previously separated algorithm for:\n",
    "1. Taking imported raw polls and converting to vote shares for every candidate in every constituency\n",
    "2. Analysing election results for a range of specified dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8acf157f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Algorithm details\n",
    "AlgorithmName = \"ComboPollElectionAlogrithm\"\n",
    "AlgorithmVersion = \"1_0\"\n",
    "AlgorithmDate = \"20240524\"\n",
    "\n",
    "# Version 0_1 initial test combination of version 1_1 of the election analysis algorithm and version 3_1 of the poll analysis algorithm\n",
    "# Version 0_2 incorporates a loop around different analysis dates and the ability to delete analyses if they already exist for a particular date\n",
    "# Version 0_3 includes a check to use as the analysis start date: the next date after the last date analysed in the database OR the date of the earliest poll to added, whichever is sooner\n",
    "# Version 0_4 check of validity periods no incorporated into the overall loop so it changes for each analysis date\n",
    "# Version 1_0 First full version after testing previous incorporations\n",
    "\n",
    "# Construct PollAnalysisAlogrithm string\n",
    "ElectionAnalysisAlgorithm = AlgorithmName + \"_\" + AlgorithmVersion + \"_\" + AlgorithmDate\n",
    "PollAnalysisAlgorithm = AlgorithmName + \"_\" + AlgorithmVersion + \"_\" + AlgorithmDate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76f9782b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required modules\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from datetime import timedelta\n",
    "import numpy as np\n",
    "import pyodbc\n",
    "import sqlalchemy\n",
    "from sqlalchemy import create_engine\n",
    "import urllib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d84e1879",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set core variables for the rest of the algorithm\n",
    "ElectionDate = datetime.date(2024, 7, 4) # Set the date of the election\n",
    "\n",
    "AutoStartDateFlag = True # if true, use the next date after the last date analysed in the database\n",
    "# OR the date of the earliest poll to added, whichever is sooner\n",
    "AutoEndDateFlag = True # if true, use the date of the last poll\n",
    "\n",
    "ManualStartDate = datetime.date(2024, 1, 1) # start date of election analyses if auto is not used\n",
    "ManualEndDate = datetime.date(2024, 5, 23) # end date of election analyses if auto is not used\n",
    "\n",
    "DeleteAnalysesFlag = True # if true, already existing analyses will be delete\n",
    "\n",
    "DetailedRankThreshold = 5 # Variable for identifying from a poll's rank, whether it is a 'national' or 'detailed' poll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a19306b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connect to database 'UK_General_Election' using SQlAlchemy\n",
    "connection_str = \"DRIVER={SQL SERVER};SERVER=DANZPOOTA;DATABASE=UK_General_Election;TRUSTED_CONNECTION=YES\"\n",
    "params = urllib.parse.quote_plus(connection_str)\n",
    "engine = create_engine('mssql+pyodbc:///?odbc_connect=%s' % params)\n",
    "conn = engine.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "270dcee8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-01\n",
      "2024-05-23\n"
     ]
    }
   ],
   "source": [
    "# Determine the start and end date for the election analysis loop\n",
    "if AutoStartDateFlag == False:\n",
    "    StartDate = ManualStartDate\n",
    "else:\n",
    "    LastAnalysisDateQuery = \"SELECT TOP(1) ElectionPredictionDate FROM ElectionPredictionMeta ORDER BY ElectionPredictionDate DESC\"\n",
    "    LastAnalysisDateList = [i[0] for i in engine.execute(LastAnalysisDateQuery)]\n",
    "    LastAnalysisDate = LastAnalysisDateList[0]\n",
    "    \n",
    "    EarliestNewPollQuery = \"SELECT TOP(1) pm.PollDate from PollMeta AS pm LEFT JOIN PollAnalysisMeta AS pam ON pm.PollID = pam.PollID WHERE pam.PollID IS NULL ORDER BY pm.PollDate ASC\"\n",
    "    EarliestNewPollList = [i[0] for i in engine.execute(EarliestNewPollQuery)]\n",
    "    EarliestNewPollDate = EarliestNewPollList[0]\n",
    "    \n",
    "    if LastAnalysisDate > EarliestNewPollDate:\n",
    "        StartDate = pd.to_datetime(EarliestNewPollDate).date()\n",
    "    else:    \n",
    "        StartDate = pd.to_datetime(LastAnalysisDate).date() + timedelta(days=1)\n",
    "    \n",
    "if AutoEndDateFlag == False:\n",
    "    EndDate = ManualEndDate\n",
    "else:\n",
    "    LastPollDateQuery = \"\"\"SELECT TOP(1) pm.PollDate FROM PollAnalysisMeta AS pam\n",
    "    INNER JOIN PollMeta AS pm ON pm.PollID = pam.PollID\n",
    "    INNER JOIN RegionTypes AS rt ON rt.RegionType = pm.PollType\n",
    "    ORDER BY pm.PollDate DESC\"\"\"\n",
    "    LastPollDateList = [i[0] for i in engine.execute(LastPollDateQuery)]\n",
    "    LastPollDate = LastPollDateList[0]\n",
    "    EndDate = pd.to_datetime(LastPollDate).date()\n",
    "    \n",
    "print(StartDate)\n",
    "print(EndDate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5017d5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine validity of polls\n",
    "# Move to the main elections analysis loop\n",
    "ElectionPredictionDate = StartDate\n",
    "\n",
    "DaysToElection = ElectionDate - ElectionPredictionDate\n",
    "if DaysToElection.days < 31:\n",
    "    NationalValidPeriod = 7\n",
    "    DetailedValidPeriod = 30\n",
    "else:\n",
    "    NationalValidPeriod = 30\n",
    "    DetailedValidPeriod = 90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33186d3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get list of unanalysed polls to the loop around\n",
    "PollsListQuery = \"SELECT A.PollID from PollMeta A LEFT JOIN PollAnalysisMeta B ON A.PollID = B.PollID WHERE B.PollID IS NULL\"\n",
    "PollsList = [i[0] for i in engine.execute(PollsListQuery)]\n",
    "PollsList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4204e71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Main algorithm loop to convert poll vote shres into candidate vote shares\n",
    "for PollID in PollsList:\n",
    "    \n",
    "    # Get the Poll Meta data from the database    \n",
    "    PollMetaQuery = \"SELECT * From PollMeta WHERE PollID = '<PollID>'\"\n",
    "    PollMetaQuery = PollMetaQuery.replace(\"<PollID>\",PollID)\n",
    "    PollMeta_df = pd.read_sql(PollMetaQuery,conn)\n",
    "    \n",
    "    # Get key variables for polls\n",
    "    PollType = PollMeta_df.at[0,'PollType']\n",
    "    PollScope = PollMeta_df.at[0,'PollScope']    \n",
    "    \n",
    "    #Query for generating list of applicable poll regions\n",
    "    AllRegionsQuery = \"SELECT RegionName FROM RegionRegionTypes WHERE RegionType = '<PollType>'\"\n",
    "    \n",
    "    # Get from database all of the region vote shares relating to the PollID\n",
    "    PollSharesQuery = \"SELECT PollDetailsID, RegionName, Party, VoteShare AS PollShare FROM PollDetails WHERE PollID = '<PollID>' ORDER BY RegionName, Party\"\n",
    "    PollSharesQuery = PollSharesQuery.replace(\"<PollID>\",PollID)\n",
    "    PollShares_df = pd.read_sql(PollSharesQuery,conn)\n",
    "    \n",
    "    # Check to see if it is a constituency only poll as this needs to be handled very differently\n",
    "    # The alogrithm cannot be allowed to look for region shares as it will not find any for a constituency poll\n",
    "    if PollType == \"Constituency\":\n",
    "        ConstituencyPollFlag = True\n",
    "\n",
    "        PreviousRegionSharesQuery = \"SELECT CandidateID, Constituency, Party, PreviousShare FROM Candidates WHERE Constituency = '<Constituency>'\"\n",
    "        PreviousRegionSharesQuery = PreviousRegionSharesQuery.replace(\"<Constituency>\",PollScope)\n",
    "        PreviousRegionShares_df = pd.read_sql(PreviousRegionSharesQuery,conn)\n",
    "        \n",
    "        ConstituencyPollRegion = PollShares_df.at[0,'RegionName']\n",
    "        \n",
    "        PreviousRegionShares_df['RegionParty'] = ConstituencyPollRegion + PreviousRegionShares_df['Party']\n",
    "        PollShares_df['RegionParty'] = PollShares_df['RegionName'] + PollShares_df['Party']\n",
    "        \n",
    "    else:\n",
    "        ConstituencyPollFlag = False\n",
    "        \n",
    "        # Generate a list of all of the regions applicable to a poll when it is not a constituency one\n",
    "        if PollScope == \"All\":\n",
    "            AllRegionsQuery = AllRegionsQuery.replace(\"<PollType>\",PollType)\n",
    "            RegionsList = [i[0] for i in engine.execute(AllRegionsQuery)]\n",
    "        else:\n",
    "            RegionsList = [PollScope]     \n",
    "\n",
    "        # Query for the region vote shares from the previous election\n",
    "        PreviousRegionSharesQuery = \"\"\"SELECT r.RegionName, can.Party, SUM(can.PreviousVotes) AS 'TotalVotes',\n",
    "        CAST(SUM(can.PreviousVotes) AS FLOAT) / SUM(SUM(can.PreviousVotes)) OVER() AS 'RawPreviousShare',\n",
    "        SUM(can.PreviousStanding) AS 'PreviousCandidates',\n",
    "        SUM(can.CurrentStanding) AS 'CurrentCandidates'\n",
    "        FROM Candidates AS can\n",
    "        INNER JOIN Constituencies as con ON con.ConstituencyName = can.Constituency\n",
    "        INNER JOIN RegionConstituencies AS rc ON  rc.ConstituencyName = con.ConstituencyName\n",
    "        INNER JOIN Regions AS r ON r.RegionName = rc.RegionName\n",
    "        INNER JOIN RegionRegionTypes AS rrt ON rrt.RegionName = r.RegionName\n",
    "        WHERE r.RegionName = '<RegionName>' AND rrt.RegionType = '<RegionType>'\n",
    "        GROUP BY r.RegionName, can.Party\n",
    "        ORDER BY r.RegionName, can.Party\"\"\"\n",
    "\n",
    "        PreviousRegionSharesQuery = PreviousRegionSharesQuery.replace(\"<RegionType>\",PollType)\n",
    "\n",
    "        # Get from database all of the vote shares for the poll regions from the previous election\n",
    "        PreviousRegionShares_df = pd.DataFrame(columns=[\"RegionName\",\"Party\",\"TotalVotes\",\"RawPreviousShare\",\"PreviousCandidates\",\"CurrentCandidates\"])\n",
    "\n",
    "        # Loop through all regions applicable to this particular poll\n",
    "        for Region in RegionsList:\n",
    "            # Run query for the raw previous region shares\n",
    "            ModRegionSharesQuery = PreviousRegionSharesQuery.replace(\"<RegionName>\",Region)\n",
    "            IndRegionShares_df = pd.read_sql(ModRegionSharesQuery,conn)  \n",
    "\n",
    "            # Join this particular region's numbers to the overall dataframe for this poll\n",
    "            PreviousRegionShares_df = pd.concat([PreviousRegionShares_df,IndRegionShares_df],axis=0)\n",
    "\n",
    "        # Reset the index column\n",
    "        PreviousRegionShares_df.reset_index(drop=True,inplace=True)\n",
    "\n",
    "        # Replace all 0 values with 1000 to ensure the new vote share can be calculated without dividing by zero\n",
    "        PreviousRegionShares_df['PreviousCandidates'].replace(0,1000,inplace=True)\n",
    "\n",
    "        #Calculated the adjusted previous share based on the number of candidates actually standing\n",
    "        PreviousRegionShares_df['PreviousShare'] = PreviousRegionShares_df['RawPreviousShare'] * PreviousRegionShares_df['CurrentCandidates']/PreviousRegionShares_df['PreviousCandidates']\n",
    "\n",
    "        # Revert previous candidates back to zero\n",
    "        PreviousRegionShares_df['PreviousCandidates'].replace(1000,0,inplace=True)\n",
    "    \n",
    "    \n",
    "        # Create a column to join the two dataframes\n",
    "        PollShares_df['RegionParty'] = PollShares_df['RegionName'] + PollShares_df['Party']\n",
    "        PreviousRegionShares_df['RegionParty'] = PreviousRegionShares_df['RegionName'] + PreviousRegionShares_df['Party']\n",
    "    \n",
    "    # Exit first constituency poll if statement\n",
    "    # Join the dataframes on 'RegionParty'\n",
    "    PreviousRegionShares_df = PreviousRegionShares_df.merge(PollShares_df[['PollDetailsID','RegionParty','PollShare']], how='left', on='RegionParty')\n",
    "\n",
    "    # Determine swing\n",
    "    PreviousRegionShares_df['Swing'] = PreviousRegionShares_df['PollShare'] - PreviousRegionShares_df['PreviousShare']\n",
    "\n",
    "    # Check if it's a constituency poll\n",
    "    if ConstituencyPollFlag == True:\n",
    "        ConstituencyShares_df = PreviousRegionShares_df.copy()\n",
    "        ConstituencyShares_df['RegionName'] = ConstituencyShares_df['Constituency']\n",
    "        \n",
    "    else:\n",
    "        # Query for pulling out previous election shares for applicable constituencies\n",
    "        CandidatesQuery = \"\"\"SELECT can.CandidateID, r.RegionName, can.Constituency, can.Party, can.PreviousShare\n",
    "        FROM Candidates AS can\n",
    "        INNER JOIN Constituencies as con ON con.ConstituencyName = can.Constituency\n",
    "        INNER JOIN RegionConstituencies AS rc ON  rc.ConstituencyName = con.ConstituencyName\n",
    "        INNER JOIN Regions AS r ON r.RegionName = rc.RegionName\n",
    "        INNER JOIN RegionRegionTypes AS rrt ON rrt.RegionName = r.RegionName\n",
    "        WHERE r.RegionName = '<RegionName>' AND rrt.RegionType = '<RegionType>'\n",
    "        AND can.CurrentStanding = 1\n",
    "        ORDER BY can.Constituency, can.Party\"\"\"\n",
    "\n",
    "        CandidatesQuery = CandidatesQuery.replace(\"<RegionType>\",PollType)\n",
    "\n",
    "        # Calculate the swings for every candidate in every constituency\n",
    "        ConstituencyShares_df = pd.DataFrame(columns=[\"CandidateID\",\"RegionName\",\"Constituency\",\"Party\",\"PreviousShare\",\"NewShareRaw\",\"VoteShare\"])\n",
    "        IndConstituencyShares_df = pd.DataFrame(columns=[\"CandidateID\",\"RegionName\",\"Constituency\",\"Party\",\"PreviousShare\",\"NewShareRaw\",\"VoteShare\"])\n",
    "\n",
    "        # Need to cycle through every region to pull out the candidates for each in turn, then get the swing for each\n",
    "        for Region in RegionsList:\n",
    "\n",
    "            ModCandidatesQuery = CandidatesQuery.replace(\"<RegionName>\",Region)\n",
    "            IndConstituencyShares_df = pd.read_sql(ModCandidatesQuery,conn)   \n",
    "\n",
    "            ConstituencyShares_df = pd.concat([ConstituencyShares_df,IndConstituencyShares_df],axis=0)\n",
    "\n",
    "        ConstituencyShares_df.reset_index(drop=True,inplace=True)\n",
    "    \n",
    "        # Create 'RegionParty' to allow merging with the previous region shares dataframe\n",
    "        ConstituencyShares_df['RegionParty'] = ConstituencyShares_df['RegionName'] + ConstituencyShares_df['Party']\n",
    "        \n",
    "        # Join the dataframes on 'RegionParty'\n",
    "        ConstituencyShares_df = ConstituencyShares_df.merge(PreviousRegionShares_df[['RegionParty','Swing']], how='left', on='RegionParty')\n",
    "\n",
    "    # Exit of 2nd constituency poll IF statement    \n",
    "    # Ensure the datatypes are numeric of the columns to be used in the calculation\n",
    "    ConstituencyShares_df[\"PreviousShare\"] = pd.to_numeric(ConstituencyShares_df[\"PreviousShare\"])\n",
    "    ConstituencyShares_df[\"Swing\"] = pd.to_numeric(ConstituencyShares_df[\"Swing\"])\n",
    "\n",
    "    ConstituencyShares_df[\"NewShareRaw\"] = ConstituencyShares_df[\"PreviousShare\"] + ConstituencyShares_df[\"Swing\"] \n",
    "    ConstituencyShares_df[\"NewShareRaw\"] = np.where(ConstituencyShares_df[\"NewShareRaw\"] < 0, 0,ConstituencyShares_df[\"NewShareRaw\"])\n",
    "\n",
    "    # Determine the factor needed to ensure vote shares for each constituency sum to 1\n",
    "    ConstituencyShares_df['ConstRawShareTotals'] = ConstituencyShares_df['NewShareRaw'].groupby(ConstituencyShares_df['Constituency']).transform('sum')\n",
    "\n",
    "    # Modify the raw vote shares to ensure they sum to 1\n",
    "    ConstituencyShares_df['VoteShare'] = ConstituencyShares_df['NewShareRaw']/ConstituencyShares_df['ConstRawShareTotals']\n",
    "\n",
    "    ConstituencyShares_df['VoteShareCheck'] = ConstituencyShares_df['VoteShare'].groupby(ConstituencyShares_df['Constituency']).transform('sum')\n",
    "\n",
    "    # Create PollAnalysisMeta details for inserting into database\n",
    "    PollAnalysisMeta_df = pd.DataFrame(columns=[\"PollID\",\"PollAnalysisDate\",\"PollAnalysisAlgorithm\"])\n",
    "\n",
    "    PollAnalysisMeta_df.at[0,\"PollID\"] = PollID\n",
    "    PollAnalysisMeta_df.at[0,\"PollAnalysisAlgorithm\"] = PollAnalysisAlgorithm\n",
    "\n",
    "    # The date of the analysis is always today's date\n",
    "    PollAnalysisMeta_df.at[0,\"PollAnalysisDate\"] = datetime.date.today()\n",
    "\n",
    "    PollAnalysisMeta_df.to_sql('PollAnalysisMeta', conn, if_exists='append', index=False)\n",
    "\n",
    "    # Initial poll analysis values are now inserted into the database to allow these to be queried for the constituency shares\n",
    "    PollAnalysisRegions_df = PreviousRegionShares_df[['PollDetailsID','Swing']].copy()\n",
    "\n",
    "    # Get the recently inserted PollAnalysis ID from the database\n",
    "    PollAnalysisIDQuery = \"SELECT PollAnalysisID FROM PollAnalysisMeta WHERE PollID = '<PollID>'\"\n",
    "    PollAnalysisIDQuery = PollAnalysisIDQuery.replace(\"<PollID>\",PollID)\n",
    "\n",
    "    PollAnalysisID = [i[0] for i in engine.execute(PollAnalysisIDQuery)][0]\n",
    "    PollAnalysisRegions_df['PollAnalysisID'] = PollAnalysisID\n",
    "\n",
    "    PollAnalysisRegions_df.to_sql('PollAnalysisRegions', conn, if_exists='append', index=False)\n",
    "    \n",
    "    # Create the dataframe for insertion into the database and insert\n",
    "    ConstituencyShares_df['PollAnalysisRegionID'] = PollID + ConstituencyShares_df['RegionParty'] + PollAnalysisID\n",
    "    PollAnalysisConstituencies_df = ConstituencyShares_df[['PollAnalysisRegionID','CandidateID','VoteShare']]\n",
    "    PollAnalysisConstituencies_df.to_sql('PollAnalysisConstituencies', conn, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "327b57a1",
   "metadata": {},
   "source": [
    "Separation between the previoulsy segragated poll analysis and election analysis algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "657e6f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "DeleteAnalysisQueryRaw = \"\"\"DELETE eppu FROM ElectionPredictionPollsUsed AS eppu\n",
    "INNER JOIN ElectionPredictionMeta AS epm ON epm.ElectionPredictionID = eppu.ElectionPredictionID\n",
    "WHERE epm.ElectionPredictionDate = '<ElectionPredictionDate>'\n",
    "\n",
    "DELETE epc FROM ElectionPredictionCandidates AS epc\n",
    "INNER JOIN ElectionPredictionMeta AS epm ON epm.ElectionPredictionID = epc.ElectionPredictionID\n",
    "WHERE epm.ElectionPredictionDate = '<ElectionPredictionDate>'\n",
    "\n",
    "DELETE epcon FROM ElectionPredictionConstituencies AS epcon\n",
    "INNER JOIN ElectionPredictionMeta AS epm ON epm.ElectionPredictionID = epcon.ElectionPredictionID\n",
    "WHERE epm.ElectionPredictionDate = '<ElectionPredictionDate>'\n",
    "\n",
    "DELETE epo FROM ElectionPredictionOverall AS epo\n",
    "INNER JOIN ElectionPredictionMeta AS epm ON epm.ElectionPredictionID = epo.ElectionPredictionID\n",
    "WHERE epm.ElectionPredictionDate = '<ElectionPredictionDate>'\n",
    "\n",
    "DELETE FROM ElectionPredictionMeta WHERE ElectionPredictionDate = '<ElectionPredictionDate>'\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aecfba44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 38.6 s\n",
      "Wall time: 14min 23s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Combined Election Analysis\n",
    "\n",
    "# Setup variables for the loop\n",
    "ElectionPredictionDate = StartDate\n",
    "Delta = timedelta(days=1)\n",
    "\n",
    "# Loop around all of the analysis dates\n",
    "while ElectionPredictionDate <= EndDate:    \n",
    "    #print(ElectionPredictionDate)\n",
    "        \n",
    "    DaysToElection = ElectionDate - ElectionPredictionDate\n",
    "    if DaysToElection.days < 31:\n",
    "        NationalValidPeriod = 7\n",
    "        DetailedValidPeriod = 30\n",
    "    else:\n",
    "        NationalValidPeriod = 30\n",
    "        DetailedValidPeriod = 90\n",
    "    \n",
    "    #print(\"Prediction Date:\",ElectionPredictionDate,\"Days To Election:\",DaysToElection.days,\"NationalValidPeriod:\",NationalValidPeriod)\n",
    "    \n",
    "    #Check if there is already an analysis for this analysis date\n",
    "    ElectionPredictionDateStr = datetime.datetime.strftime(ElectionPredictionDate, '%Y%m%d')\n",
    "    AnalysisExistsQuery = \"SELECT Count(ElectionPredictionID) FROM ElectionPredictionMeta WHERE ElectionPredictionDate = '<ElectionPredictionDate>'\"\n",
    "    AnalysisExistsQuery = AnalysisExistsQuery.replace('<ElectionPredictionDate>',ElectionPredictionDateStr)\n",
    "    AnalysisExistsList = [i[0] for i in engine.execute(AnalysisExistsQuery)]\n",
    "    AnalysisExistsInt = AnalysisExistsList[0]\n",
    "    #print(AnalysisExistsInt)\n",
    "\n",
    "    if AnalysisExistsInt < 1 or DeleteAnalysesFlag == True:\n",
    "\n",
    "        if AnalysisExistsInt >=1:\n",
    "            # Delete the analysis\n",
    "            DeleteAnalysisQuery = DeleteAnalysisQueryRaw.replace('<ElectionPredictionDate>',ElectionPredictionDateStr)\n",
    "            engine.execute(DeleteAnalysisQuery)\n",
    "    \n",
    "        # Get the list of polls that have actually been analysed and incorporated into the database\n",
    "        AnalysedPollsQuery = \"\"\"SELECT pam.PollID, pm.Pollster, pm.PollType, pm.PollScope, pm.PollDate, rt.RegionTypeRank  FROM PollAnalysisMeta AS pam\n",
    "        INNER JOIN PollMeta AS pm ON pm.PollID = pam.PollID\n",
    "        INNER JOIN RegionTypes AS rt ON rt.RegionType = pm.PollType\"\"\"\n",
    "\n",
    "        AnalysedPolls_df = pd.read_sql(AnalysedPollsQuery,conn)\n",
    "\n",
    "        # Add prediction date and convert to datetime date so that it can be used in a calcualtion\n",
    "        AnalysedPolls_df['PredictionDate'] = ElectionPredictionDate\n",
    "        AnalysedPolls_df['PredictionDate'] = pd.to_datetime(AnalysedPolls_df['PredictionDate'])\n",
    "\n",
    "        # Convert the date column to datetime type\n",
    "        AnalysedPolls_df['PollDate'] = pd.to_datetime(AnalysedPolls_df['PollDate'])\n",
    "\n",
    "        # Determine how many days from the prediction date a poll was taken\n",
    "        AnalysedPolls_df['DateDelta'] = AnalysedPolls_df['PredictionDate'] - AnalysedPolls_df['PollDate']\n",
    "\n",
    "        # Assign a rank to each poll\n",
    "        AnalysedPolls_df['PollRank'] = np.where(AnalysedPolls_df['PollScope']=='All',AnalysedPolls_df['RegionTypeRank'],AnalysedPolls_df['RegionTypeRank']-1)\n",
    "\n",
    "        # Determine the applicability of each poll based on the day delta\n",
    "        AnalysedPolls_df['PollApplicability'] = np.where((AnalysedPolls_df['DateDelta'] < pd.Timedelta(DetailedValidPeriod, unit=\"d\")) \\\n",
    "                                                         & (AnalysedPolls_df['DateDelta'] >= pd.Timedelta(0, unit=\"d\")) \\\n",
    "                                                         & (AnalysedPolls_df['PollRank'] <= DetailedRankThreshold),1, \\\n",
    "                                                         np.where((AnalysedPolls_df['DateDelta'] < pd.Timedelta(NationalValidPeriod, unit=\"d\")) \\\n",
    "                                                         & (AnalysedPolls_df['DateDelta'] >= pd.Timedelta(0, unit=\"d\")) \\\n",
    "                                                         & (AnalysedPolls_df['PollRank'] > DetailedRankThreshold),1,0))\n",
    "\n",
    "        # Copy the polls that fall within the date delta to a new data frame\n",
    "        ApplicablePolls_df = AnalysedPolls_df[AnalysedPolls_df['PollApplicability'] == 1].copy()\n",
    "        ApplicablePolls_df.reset_index(drop=True,inplace=True)\n",
    "\n",
    "        # Check for duplicate polls of the same type\n",
    "        # Create column that would contain the info to check for duplicates\n",
    "        ApplicablePolls_df['DuplicateCheck'] = ApplicablePolls_df['Pollster'] + ApplicablePolls_df['PollType'] + ApplicablePolls_df['PollScope'] \n",
    "\n",
    "        # The dataframe needs to be sorted to ensure the latest poll is kept and older duplicates are removed\n",
    "        ApplicablePolls_df.sort_values(by='DateDelta',inplace=True)\n",
    "\n",
    "        # Drop duplicates\n",
    "        ApplicablePolls_df.drop_duplicates(subset=['DuplicateCheck'],inplace=True)\n",
    "\n",
    "        # Reset the dataframe index after being sorted and duplicates removed\n",
    "        ApplicablePolls_df.reset_index(drop=True,inplace=True)\n",
    "\n",
    "        # Main algorithm to create resultant candidate shares\n",
    "        # Create dataframe with every candidate as rows\n",
    "        SelectCandidatesQuery = \"SELECT can.CandidateID, can.Constituency, can.Party, can.PreviousShare FROM Candidates AS can WHERE can.CurrentStanding = 1\"\n",
    "        Candidates_df = pd.read_sql(SelectCandidatesQuery,conn)\n",
    "\n",
    "        # Descending Loop around every rank\n",
    "        # start point = max rank from applicable polls df\n",
    "        MaxRank = ApplicablePolls_df['PollRank'].max()\n",
    "        MinRank = ApplicablePolls_df['PollRank'].min()\n",
    "\n",
    "        # Boolean to record if this is the first run through for the running total\n",
    "        FirstRun = True\n",
    "\n",
    "        for Rank in range(MaxRank,MinRank-1,-1):\n",
    "\n",
    "            # Create df from all polls relating to the current rank\n",
    "            # First create list of applicable polls\n",
    "            RankApplicablePolls_df = ApplicablePolls_df[ApplicablePolls_df['PollRank'] == Rank].copy()\n",
    "            RankApplicablePolls = RankApplicablePolls_df['PollID'].tolist()\n",
    "\n",
    "            for PollID in RankApplicablePolls:\n",
    "                # print(Rank,\":\",PollID)        \n",
    "\n",
    "                # Query for getting the poll analysis details\n",
    "                SelectPollDetailsQuery = \"\"\"SELECT pac.CandidateID, pac.VoteShare AS '<PollID>' FROM PollAnalysisConstituencies AS pac\n",
    "                INNER JOIN PollAnalysisRegions AS par on par.PollAnalysisRegionID = pac.PollAnalysisRegionID\n",
    "                INNER JOIN PollAnalysisMeta AS pam ON pam.PollAnalysisID = par.PollAnalysisID\n",
    "                WHERE pam.PollID = '<PollID>'\n",
    "                ORDER BY pac.CandidateID\"\"\"\n",
    "\n",
    "                # Insert the PollID into the query\n",
    "                SelectPollDetailsQuery = SelectPollDetailsQuery.replace(\"<PollID>\",PollID)\n",
    "\n",
    "                # Pull query into a data frame for the results\n",
    "                PollAnalysis_df = pd.read_sql(SelectPollDetailsQuery,conn)\n",
    "\n",
    "                # Merge with Candidates_df\n",
    "                # PreviousRegionShares_df = PreviousRegionShares_df.merge(PollRegionShares_df[['PollDetailsID','RegionParty','PollShare']], how='left', on='RegionParty')\n",
    "                Candidates_df = Candidates_df.merge(PollAnalysis_df, how='left', on='CandidateID')\n",
    "\n",
    "            # Average the columns for each row (candidate) for this rank\n",
    "            if RankApplicablePolls != []:\n",
    "                if FirstRun == True:\n",
    "                    Candidates_df[Rank] = Candidates_df[RankApplicablePolls].mean(axis=1)\n",
    "                    # Set the first run to false now that the loop has been gone though\n",
    "                    FirstRun = False\n",
    "                else:\n",
    "                    RankApplicablePolls.append(PreviousRank)\n",
    "                    Candidates_df[Rank] = Candidates_df[RankApplicablePolls].mean(axis=1)\n",
    "\n",
    "                # Record the last rank to be evaluated        \n",
    "                PreviousRank = Rank\n",
    "\n",
    "        Candidates_df['VoteShareRaw'] = Candidates_df[Rank].copy()\n",
    "\n",
    "        # Determine the factor needed to ensure vote shares for each constituency sum to 1\n",
    "        Candidates_df['ConstRawShareTotals'] = Candidates_df['VoteShareRaw'].groupby(Candidates_df['Constituency']).transform('sum')\n",
    "\n",
    "        # Modify the raw vote shares to ensure they sum to 1\n",
    "        Candidates_df['VoteShare'] = Candidates_df['VoteShareRaw']/Candidates_df['ConstRawShareTotals']\n",
    "\n",
    "        Candidates_df['VoteShareCheck'] = Candidates_df['VoteShare'].groupby(Candidates_df['Constituency']).transform('sum')\n",
    "\n",
    "        Candidates_df['VoteShareChange'] = Candidates_df['VoteShare'] - Candidates_df['PreviousShare']\n",
    "\n",
    "        # Determine the constituency winners\n",
    "        # https://stackoverflow.com/questions/15705630/get-the-rows-which-have-the-max-value-in-groups-using-groupby\n",
    "        #df.sort_values('count').drop_duplicates(['Sp', 'Mt'], keep='last')\n",
    "        ConstWinners_df = Candidates_df[['Constituency','Party','VoteShare','VoteShareChange']].copy()\n",
    "        ConstWinners_df = ConstWinners_df.sort_values(['Constituency','VoteShare'],ascending = [True, False])\n",
    "        ConstWinners_df['Majority'] = ConstWinners_df['VoteShare'] - ConstWinners_df['VoteShare'].shift(-1)\n",
    "        ConstWinners_df['SecondParty'] = ConstWinners_df['Party'].shift(-1)\n",
    "\n",
    "        # Calculate the swing for each winner\n",
    "        ConstWinners_df['Swing'] = (ConstWinners_df['VoteShareChange'] - ConstWinners_df['VoteShareChange'].shift(-1))/2\n",
    "\n",
    "        # Keep only the winners of each constituency\n",
    "        ConstWinners_df = ConstWinners_df.sort_values('VoteShare').drop_duplicates(['Constituency'], keep='last')\n",
    "        ConstWinners_df = ConstWinners_df.sort_values('Constituency')\n",
    "\n",
    "        ConstWinners_df.reset_index(drop=True,inplace=True)\n",
    "\n",
    "        # Determine how many constituencies each party has won\n",
    "        OverallResults_df = ConstWinners_df[['Party','Constituency']].groupby('Party').count()\n",
    "        OverallResults_df.reset_index(drop=False,inplace=True)\n",
    "\n",
    "        # Determine total vote shares for each party\n",
    "        OverallVoteShare_df = Candidates_df[['Party','VoteShare']].copy()\n",
    "        OverallVoteShare_df['PartyShare'] = OverallVoteShare_df['VoteShare'].groupby(OverallVoteShare_df['Party']).transform('sum')\n",
    "        OverallVoteShare_df = OverallVoteShare_df.drop_duplicates(['Party'], keep='last')\n",
    "        OverallVoteShare_df.drop(['VoteShare'], axis=1, inplace=True)\n",
    "        OverallVoteShare_df.sort_values(by='PartyShare', ascending=False, inplace=True)\n",
    "        OverallVoteShare_df['PartyShare'] = OverallVoteShare_df['PartyShare']/OverallVoteShare_df['PartyShare'].sum()\n",
    "        OverallVoteShare_df.reset_index(drop=True,inplace=True)\n",
    "\n",
    "        # Combine the overall vote shares and constituency numbers into one dataframe\n",
    "        Overall_df = OverallVoteShare_df.merge(OverallResults_df, how='left', on='Party')\n",
    "        Overall_df = Overall_df.fillna(0)\n",
    "        Overall_df.sort_values(by='Constituency', ascending=False, inplace=True)\n",
    "        Overall_df.reset_index(drop=True,inplace=True)\n",
    "\n",
    "        # Election prediction analysis date is today\n",
    "        ElectionAnalysisDate = datetime.date.today()\n",
    "\n",
    "        # Create the election prediction ID for the database\n",
    "        ElectionPredictionID = datetime.datetime.strftime(ElectionAnalysisDate, '%Y%m%d') + datetime.datetime.strftime(ElectionPredictionDate, '%Y%m%d') + ElectionAnalysisAlgorithm\n",
    "\n",
    "        # Create the ElectionPredictionMeta table content for this analysis\n",
    "        ElectionPredictionMeta_df = pd.DataFrame(columns=[\"ElectionAnalysisDate\",\"ElectionPredictionDate\",\"ElectionAnalysisAlgorithm\"])\n",
    "        ElectionPredictionMeta_df.at[0,\"ElectionAnalysisDate\"] = ElectionAnalysisDate\n",
    "        ElectionPredictionMeta_df.at[0,\"ElectionPredictionDate\"] = ElectionPredictionDate\n",
    "        ElectionPredictionMeta_df.at[0,\"ElectionAnalysisAlgorithm\"] = ElectionAnalysisAlgorithm\n",
    "\n",
    "        # Create the ElectionPredictionPolls used content\n",
    "        ElectionPredictionPollsUsed_df = pd.DataFrame(columns=['ElectionPredictionID','PollID'])\n",
    "        ElectionPredictionPollsUsed_df['PollID'] = ApplicablePolls_df['PollID'].copy()\n",
    "        ElectionPredictionPollsUsed_df['ElectionPredictionID'] = ElectionPredictionID\n",
    "\n",
    "        # Create ElectionPredictionCandidates data\n",
    "        ElectionPredictionCandidates_df = pd.DataFrame(columns=['ElectionPredictionID','CandidateID','VoteShare'])\n",
    "        ElectionPredictionCandidates_df[['CandidateID','VoteShare']] = Candidates_df[['CandidateID','VoteShare']].copy()\n",
    "        ElectionPredictionCandidates_df['ElectionPredictionID'] = ElectionPredictionID\n",
    "\n",
    "        # Create ElectionPredictionConstituencies data\n",
    "        ElectionPredictionConstituencies_df = pd.DataFrame(columns=['ElectionPredictionID','Constituency','WinningParty','SecondParty','VoteShare','Majority','GAIN','LOSS','Swing'])\n",
    "        ElectionPredictionConstituencies_df[['Constituency','WinningParty','SecondParty','VoteShare','Majority','Swing']] = ConstWinners_df[['Constituency','Party','SecondParty','VoteShare','Majority','Swing']].copy()\n",
    "\n",
    "        PreviousWinnersQuery = \"SELECT ConstituencyName AS 'Constituency', FirstParty AS 'PreviousWinner' FROM Constituencies\"\n",
    "        PreviousWinners_df = pd.read_sql(PreviousWinnersQuery,conn)\n",
    "        ElectionPredictionConstituencies_df = ElectionPredictionConstituencies_df.merge(PreviousWinners_df, how='left', on='Constituency')\n",
    "        ElectionPredictionConstituencies_df['GAIN'] = np.where(ElectionPredictionConstituencies_df['WinningParty'] == ElectionPredictionConstituencies_df['PreviousWinner'],ElectionPredictionConstituencies_df['WinningParty']+\" HOLD\",ElectionPredictionConstituencies_df['WinningParty']+\" GAIN\")\n",
    "        ElectionPredictionConstituencies_df['LOSS'] = np.where(ElectionPredictionConstituencies_df['WinningParty'] == ElectionPredictionConstituencies_df['PreviousWinner'],ElectionPredictionConstituencies_df['PreviousWinner']+\" HOLD\",ElectionPredictionConstituencies_df['PreviousWinner']+\" LOSS\")\n",
    "        ElectionPredictionConstituencies_df['ElectionPredictionID'] = ElectionPredictionID\n",
    "\n",
    "        # Create ElectionPredictionOverall data\n",
    "        ElectionPredictionOverall_df = pd.DataFrame(columns=['ElectionPredictionID','Party','VoteShare','Constituencies'])\n",
    "        ElectionPredictionOverall_df[['Party','VoteShare','Constituencies']] = Overall_df[['Party','PartyShare','Constituency']].copy()\n",
    "        ElectionPredictionOverall_df['Constituencies'] = ElectionPredictionOverall_df['Constituencies'].astype('int')\n",
    "        ElectionPredictionOverall_df['ElectionPredictionID'] = ElectionPredictionID\n",
    "\n",
    "        # Insert data into the database\n",
    "        ElectionPredictionMeta_df.to_sql('ElectionPredictionMeta', conn, if_exists='append', index=False)\n",
    "        ElectionPredictionPollsUsed_df.to_sql('ElectionPredictionPollsUsed', conn, if_exists='append', index=False)\n",
    "        ElectionPredictionCandidates_df.to_sql('ElectionPredictionCandidates', conn, if_exists='append', index=False)\n",
    "        ElectionPredictionConstituencies_df.to_sql('ElectionPredictionConstituencies', conn, if_exists='append', index=False)\n",
    "        ElectionPredictionOverall_df.to_sql('ElectionPredictionOverall', conn, if_exists='append', index=False)\n",
    "    \n",
    "    ElectionPredictionDate += Delta # Increment ElectionPredictionDate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "434a6c04",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CandidateID</th>\n",
       "      <th>Constituency</th>\n",
       "      <th>Party</th>\n",
       "      <th>PreviousShare</th>\n",
       "      <th>20240523TechneGBAll</th>\n",
       "      <th>8</th>\n",
       "      <th>20240523More in CommonITL1Region-NINAAll</th>\n",
       "      <th>20240522SurvationGBSixAll</th>\n",
       "      <th>20240522YouGovGBSixAll</th>\n",
       "      <th>20240520DeltapollGBSixAll</th>\n",
       "      <th>...</th>\n",
       "      <th>20240326SurvationLondonFiveAll</th>\n",
       "      <th>20240302More in CommonMICBlueWallAll</th>\n",
       "      <th>4</th>\n",
       "      <th>20240419TechneConstituencyPortsmouth North</th>\n",
       "      <th>1</th>\n",
       "      <th>VoteShareRaw</th>\n",
       "      <th>ConstRawShareTotals</th>\n",
       "      <th>VoteShare</th>\n",
       "      <th>VoteShareCheck</th>\n",
       "      <th>VoteShareChange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aberafan MaestegCon</td>\n",
       "      <td>Aberafan Maesteg</td>\n",
       "      <td>Con</td>\n",
       "      <td>0.226279</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.103941</td>\n",
       "      <td>0.140839</td>\n",
       "      <td>0.087108</td>\n",
       "      <td>0.067328</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.068545</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.068545</td>\n",
       "      <td>0.068545</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.068545</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.157734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aberafan MaestegGreen</td>\n",
       "      <td>Aberafan Maesteg</td>\n",
       "      <td>Green</td>\n",
       "      <td>0.015780</td>\n",
       "      <td>0.034414</td>\n",
       "      <td>0.034414</td>\n",
       "      <td>0.068041</td>\n",
       "      <td>0.060957</td>\n",
       "      <td>0.071516</td>\n",
       "      <td>0.020738</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.099767</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.099767</td>\n",
       "      <td>0.099767</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.099767</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.083987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Aberafan MaestegLab</td>\n",
       "      <td>Aberafan Maesteg</td>\n",
       "      <td>Lab</td>\n",
       "      <td>0.529208</td>\n",
       "      <td>0.639477</td>\n",
       "      <td>0.639477</td>\n",
       "      <td>0.580561</td>\n",
       "      <td>0.636022</td>\n",
       "      <td>0.540176</td>\n",
       "      <td>0.637649</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.557456</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.557456</td>\n",
       "      <td>0.557456</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.557456</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.028249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aberafan MaestegLD</td>\n",
       "      <td>Aberafan Maesteg</td>\n",
       "      <td>LD</td>\n",
       "      <td>0.037030</td>\n",
       "      <td>0.036098</td>\n",
       "      <td>0.036098</td>\n",
       "      <td>0.079222</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.062920</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.033332</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.033332</td>\n",
       "      <td>0.033332</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.033332</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.003698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Aberafan MaestegOther</td>\n",
       "      <td>Aberafan Maesteg</td>\n",
       "      <td>Other</td>\n",
       "      <td>0.016455</td>\n",
       "      <td>0.013308</td>\n",
       "      <td>0.013308</td>\n",
       "      <td>0.000669</td>\n",
       "      <td>0.000654</td>\n",
       "      <td>0.010856</td>\n",
       "      <td>0.000669</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.007049</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.007049</td>\n",
       "      <td>0.007049</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.007049</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.009406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Aberafan MaestegPC</td>\n",
       "      <td>Aberafan Maesteg</td>\n",
       "      <td>PC</td>\n",
       "      <td>0.089841</td>\n",
       "      <td>0.093205</td>\n",
       "      <td>0.093205</td>\n",
       "      <td>0.041988</td>\n",
       "      <td>0.108421</td>\n",
       "      <td>0.038119</td>\n",
       "      <td>0.141319</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.054643</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.054643</td>\n",
       "      <td>0.054643</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.054643</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.035198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Aberafan MaestegReform</td>\n",
       "      <td>Aberafan Maesteg</td>\n",
       "      <td>Reform</td>\n",
       "      <td>0.085406</td>\n",
       "      <td>0.183499</td>\n",
       "      <td>0.183499</td>\n",
       "      <td>0.125578</td>\n",
       "      <td>0.053108</td>\n",
       "      <td>0.252225</td>\n",
       "      <td>0.069377</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.179207</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.179207</td>\n",
       "      <td>0.179207</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.179207</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.093801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Aberdeen NorthCon</td>\n",
       "      <td>Aberdeen North</td>\n",
       "      <td>Con</td>\n",
       "      <td>0.245496</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.183162</td>\n",
       "      <td>0.152525</td>\n",
       "      <td>0.157544</td>\n",
       "      <td>0.145967</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.110433</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.110433</td>\n",
       "      <td>0.110433</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.110433</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.135064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Aberdeen NorthGreen</td>\n",
       "      <td>Aberdeen North</td>\n",
       "      <td>Green</td>\n",
       "      <td>0.012209</td>\n",
       "      <td>0.032201</td>\n",
       "      <td>0.032201</td>\n",
       "      <td>0.020607</td>\n",
       "      <td>0.009559</td>\n",
       "      <td>0.085795</td>\n",
       "      <td>0.034436</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.027781</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.027781</td>\n",
       "      <td>0.027781</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.027781</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.015572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Aberdeen NorthLab</td>\n",
       "      <td>Aberdeen North</td>\n",
       "      <td>Lab</td>\n",
       "      <td>0.119796</td>\n",
       "      <td>0.246793</td>\n",
       "      <td>0.246793</td>\n",
       "      <td>0.261893</td>\n",
       "      <td>0.323848</td>\n",
       "      <td>0.279968</td>\n",
       "      <td>0.267252</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.333540</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.333540</td>\n",
       "      <td>0.333540</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333540</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.213744</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              CandidateID      Constituency   Party  PreviousShare  \\\n",
       "0     Aberafan MaestegCon  Aberafan Maesteg     Con       0.226279   \n",
       "1   Aberafan MaestegGreen  Aberafan Maesteg   Green       0.015780   \n",
       "2     Aberafan MaestegLab  Aberafan Maesteg     Lab       0.529208   \n",
       "3      Aberafan MaestegLD  Aberafan Maesteg      LD       0.037030   \n",
       "4   Aberafan MaestegOther  Aberafan Maesteg   Other       0.016455   \n",
       "5      Aberafan MaestegPC  Aberafan Maesteg      PC       0.089841   \n",
       "6  Aberafan MaestegReform  Aberafan Maesteg  Reform       0.085406   \n",
       "7       Aberdeen NorthCon    Aberdeen North     Con       0.245496   \n",
       "8     Aberdeen NorthGreen    Aberdeen North   Green       0.012209   \n",
       "9       Aberdeen NorthLab    Aberdeen North     Lab       0.119796   \n",
       "\n",
       "   20240523TechneGBAll         8  20240523More in CommonITL1Region-NINAAll  \\\n",
       "0             0.000000  0.000000                                  0.103941   \n",
       "1             0.034414  0.034414                                  0.068041   \n",
       "2             0.639477  0.639477                                  0.580561   \n",
       "3             0.036098  0.036098                                  0.079222   \n",
       "4             0.013308  0.013308                                  0.000669   \n",
       "5             0.093205  0.093205                                  0.041988   \n",
       "6             0.183499  0.183499                                  0.125578   \n",
       "7             0.000000  0.000000                                  0.183162   \n",
       "8             0.032201  0.032201                                  0.020607   \n",
       "9             0.246793  0.246793                                  0.261893   \n",
       "\n",
       "   20240522SurvationGBSixAll  20240522YouGovGBSixAll  \\\n",
       "0                   0.140839                0.087108   \n",
       "1                   0.060957                0.071516   \n",
       "2                   0.636022                0.540176   \n",
       "3                   0.000000                0.000000   \n",
       "4                   0.000654                0.010856   \n",
       "5                   0.108421                0.038119   \n",
       "6                   0.053108                0.252225   \n",
       "7                   0.152525                0.157544   \n",
       "8                   0.009559                0.085795   \n",
       "9                   0.323848                0.279968   \n",
       "\n",
       "   20240520DeltapollGBSixAll  ...  20240326SurvationLondonFiveAll  \\\n",
       "0                   0.067328  ...                             NaN   \n",
       "1                   0.020738  ...                             NaN   \n",
       "2                   0.637649  ...                             NaN   \n",
       "3                   0.062920  ...                             NaN   \n",
       "4                   0.000669  ...                             NaN   \n",
       "5                   0.141319  ...                             NaN   \n",
       "6                   0.069377  ...                             NaN   \n",
       "7                   0.145967  ...                             NaN   \n",
       "8                   0.034436  ...                             NaN   \n",
       "9                   0.267252  ...                             NaN   \n",
       "\n",
       "   20240302More in CommonMICBlueWallAll         4  \\\n",
       "0                                   NaN  0.068545   \n",
       "1                                   NaN  0.099767   \n",
       "2                                   NaN  0.557456   \n",
       "3                                   NaN  0.033332   \n",
       "4                                   NaN  0.007049   \n",
       "5                                   NaN  0.054643   \n",
       "6                                   NaN  0.179207   \n",
       "7                                   NaN  0.110433   \n",
       "8                                   NaN  0.027781   \n",
       "9                                   NaN  0.333540   \n",
       "\n",
       "   20240419TechneConstituencyPortsmouth North         1  VoteShareRaw  \\\n",
       "0                                         NaN  0.068545      0.068545   \n",
       "1                                         NaN  0.099767      0.099767   \n",
       "2                                         NaN  0.557456      0.557456   \n",
       "3                                         NaN  0.033332      0.033332   \n",
       "4                                         NaN  0.007049      0.007049   \n",
       "5                                         NaN  0.054643      0.054643   \n",
       "6                                         NaN  0.179207      0.179207   \n",
       "7                                         NaN  0.110433      0.110433   \n",
       "8                                         NaN  0.027781      0.027781   \n",
       "9                                         NaN  0.333540      0.333540   \n",
       "\n",
       "   ConstRawShareTotals  VoteShare  VoteShareCheck  VoteShareChange  \n",
       "0                  1.0   0.068545             1.0        -0.157734  \n",
       "1                  1.0   0.099767             1.0         0.083987  \n",
       "2                  1.0   0.557456             1.0         0.028249  \n",
       "3                  1.0   0.033332             1.0        -0.003698  \n",
       "4                  1.0   0.007049             1.0        -0.009406  \n",
       "5                  1.0   0.054643             1.0        -0.035198  \n",
       "6                  1.0   0.179207             1.0         0.093801  \n",
       "7                  1.0   0.110433             1.0        -0.135064  \n",
       "8                  1.0   0.027781             1.0         0.015572  \n",
       "9                  1.0   0.333540             1.0         0.213744  \n",
       "\n",
       "[10 rows x 44 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Candidates_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ca5e63ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Party</th>\n",
       "      <th>PartyShare</th>\n",
       "      <th>Constituency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lab</td>\n",
       "      <td>0.443212</td>\n",
       "      <td>458.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Con</td>\n",
       "      <td>0.234212</td>\n",
       "      <td>133.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LD</td>\n",
       "      <td>0.090546</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SNP</td>\n",
       "      <td>0.027109</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DUP</td>\n",
       "      <td>0.006891</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SF</td>\n",
       "      <td>0.007975</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PC</td>\n",
       "      <td>0.003769</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Other</td>\n",
       "      <td>0.014731</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SDLP</td>\n",
       "      <td>0.002571</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Green</td>\n",
       "      <td>0.059232</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>APNI</td>\n",
       "      <td>0.004367</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Reform</td>\n",
       "      <td>0.102287</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>UUP</td>\n",
       "      <td>0.003098</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Party  PartyShare  Constituency\n",
       "0      Lab    0.443212         458.0\n",
       "1      Con    0.234212         133.0\n",
       "2       LD    0.090546          27.0\n",
       "3      SNP    0.027109           8.0\n",
       "4      DUP    0.006891           8.0\n",
       "5       SF    0.007975           7.0\n",
       "6       PC    0.003769           3.0\n",
       "7    Other    0.014731           2.0\n",
       "8     SDLP    0.002571           2.0\n",
       "9    Green    0.059232           1.0\n",
       "10    APNI    0.004367           1.0\n",
       "11  Reform    0.102287           0.0\n",
       "12     UUP    0.003098           0.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Overall_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "149a023a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the candidates dataframe to a csv for testing\n",
    "#Candidates_df.to_csv('C:/Users/danmu/Documents/Elections/2024_Python/candidates.csv',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c2add402",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Close the connection with the database\n",
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
